{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 융합교육 (수학교육용 데이터 수집 + 선처리 +  AI 코딩) \n",
    "\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "    \n",
    "# 스마트 수학교육"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++ 코로나 사태로 아래 5개  ipynb 실습 위주로 진행 ++\n",
    "\n",
    "<p> &nbsp;\n",
    "\n",
    "# 목표는 수학교육용 챗봇을 위한 학습데이터 수집과 조작\n",
    "\n",
    "# 이를 목표로 우선 학생들이 개별적으로 ipynb 실습을 하고, \n",
    "\n",
    "# 교실 수업에서 발표 토론을 하며 챗봇을 복습하며 설계한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차 (Table of Contents)\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "**토이 탐구실험** - 수학교육용 챗봇을 위한 기본적인 경험을 얻는 탐구실험입니다.\n",
    "\n",
    "0. [바비 토이코드](./0.Keras-Babi_MathQA.ipynb)\n",
    "\n",
    "    \n",
    "[참고 : 학부 파이썬과 Graph](./U1.Python-Graph_Game.ipynb)\n",
    "    \n",
    "[참고 : 학부 텐서플로우와 MinMax 최적화](./U2.TF-DNN_MinMax.ipynb) \n",
    "\n",
    "**자연어 처리 기본** - 텐서플로우 코딩과 딥러닝의 개념을 얻는 학습용 챕터입니다.\n",
    "\n",
    "1. [RNN CNN 덧셈AI](./1.TF-Keras_RnnAddition.ipynb)\n",
    "\n",
    "2. [데이터와 코딩](./2.TF-Keras_IrisEstimator.ipynb)\n",
    "\n",
    "\n",
    "**자연어 처리 심화** - 한글 처리와 한글 챗봇을 설계하는 학기말 과제를 위한 챕터입니다.\n",
    "\n",
    "3. [챗봇 Tools](./3.SK-Konlpy-Matplotlib.ipynb)\n",
    "\n",
    "4. [챗봇 만들기](./4.TF-NMT_CHATBOT.ipynb)\n",
    "\n",
    "\n",
    "**학기말 과제 수행** - 한글 처리와 한글 챗봇 코드를 바탕으로 학기말 과제를 수행합니다.\n",
    "    \n",
    "    \n",
    "5. [한글 CHATBOT](./5.교재한글CHATBOT.ipynb)\n",
    "\n",
    "6. [한글 Transformer](./6.교재한글Transformer.ipynb)\n",
    " \n",
    "0. [Babi CHATBOT](./0.Keras-Babi_MathQA.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "# ++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n",
    "#  다음 순서로 자연어 처리와 AI 수학교육 융합을 다룬다\n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n",
    "## (강의) 교재 1,2,3장과 6장 관련된 5개의 ipynb 실습+학습 \n",
    "## (평가) Babi, RNN 덧셈, 챗봇과 어텐션 코드의 이해와 적용\n",
    "    \n",
    "#### +++\n",
    "    \n",
    "### 0.ipynb : 수학교육 활용을 위한 질문답변 Babi 챗봇 소개\n",
    "#### (평가) 0.ipynb Babi 코드의 작동 원리를 바탕으로, 1 - 2 - 3 - 4 ipynb 탐구한다.\n",
    " \n",
    "#### +++\n",
    "    \n",
    "### 1.pynb : 교재의 기본 내용을 데이터 기반의 딥러닝으로 소개\n",
    "#### (평가) 1.ipynb 는 덧셈 RNN 딥러닝을 중심으로 딥러닝 개념과 코드를 익힌다\n",
    "\n",
    "#### +++\n",
    "    \n",
    "### 2.pynb : 교재의 텐서플로우 estimator 를 iris 데이터로 소개\n",
    "\n",
    "        \n",
    "#### (발표) 중간고사 이후에 팀별 발표\n",
    "    \n",
    "#### +++\n",
    "    \n",
    "### 3.ipynb : 교재의 한글 자연어 처리법과 데이터 분석을 소개¶\n",
    "    \n",
    "#### (발표) 중간고사 이후에 팀별 발표\n",
    "    \n",
    "#### +++\n",
    "    \n",
    "### 4.ipynb : 수학교육 활용을 위한 질문답변 한글 챗봇 소개\n",
    "#### (평가) 한글 챗봇과 어텐션 학습후, 0.ipynb 4.ipynb 5 와 6 ipynb 기반으로 과제를 구상 ! \n",
    " \n",
    "#### +++\n",
    "<p> &nbsp;    \n",
    "    \n",
    "## (5월 중간고사) 먼저 학습한 것에 대한 openbook 필기시험\n",
    "### 평가목표 : 딥러닝 작동 원리와 데이터 선처리 방법을 설명할 수 있다\n",
    "### Babi, RNN 덧셈, 그리고 챗봇 코드와 어텐션 코드 등의 작동원리 설명 \n",
    "    \n",
    "<p> &nbsp;    \n",
    "    \n",
    "## (다음) 팀별로 교재 4장, 5장, 6장의 ipynb 를 기반으로 발료\n",
    "### 주안점 : 자연어 처리의 문제에 대한 데이터 수집과 분석 방법\n",
    "### 수학교육 챗봇 및 텐서플로우 2.0 버젼으로의 변환을 목표로 !\n",
    "    \n",
    "<p> &nbsp;    \n",
    "    \n",
    "## (6월 학기말 과제) 자연어처리와 수학교육 융합에 대한 학기말 과제\n",
    "### 평가목표 : 학습데이터를 수집하여 수학교육 관련 챗봇을 설계한다 \n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# +++++++ AI 와 수학교육의 예 +++++++\n",
    "\n",
    "\n",
    "#  인공지능  덧셈 학습과 인간의 덧셈 학습\n",
    "\n",
    "\n",
    "## 초등생의 덧셈 학습과 유사한점 다른점은 무엇 ??\n",
    "\n",
    "## 인공지능의 학습과 인간의 학습의 상호 연관성 ??\n",
    "\n",
    "# ++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "## 언라인 서치로 인공지능과 수학교육을 찾아본다\n",
    "\n",
    "예를 들어, 디렉리에 들어있는 논문을 보고 비슷한 것을 찾아본다\n",
    "\n",
    "그런 연구를 하는 곳을 찾아본다 : 예 https://ariannayuan.github.io/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 먼저 사용할 데이터와 tensorflow 사용법을 익히자\n",
    "\n",
    "\n",
    "# (목표) AI  코드를 설명하고 데이터를 조작할 수 있다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> &nbsp;\n",
    "\n",
    "# ++++++++++++++++++++++++++++++\n",
    "\n",
    "#  Data 기반 텐서플로우 사용법 (1)  (2) (3) (4) (5) 실습\n",
    "\n",
    "### (1)  Numpy 텐서플로우 XOR 뉴럴네트워크 익히기\n",
    "\n",
    "### (2) 텐서플로우 CNN 신경망 (mnist 데이터)\n",
    "    \n",
    "### (3) 케라스를 활용한 자연어처리 익히기 (한글 챗봇 데이터) \n",
    "\n",
    "### (4) 아기 Baby RNN 익히기\n",
    "    \n",
    "### (5) RNN+CNN 텍스트 분석 익히기(imdb 데이터)\n",
    "    \n",
    "# ++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "\n",
    "\n",
    "동영상 자료 :\n",
    "    \n",
    "https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU\n",
    "    \n",
    "    \n",
    "https://end-to-end-machine-learning.teachable.com/courses/how-deep-neural-networks-work/lectures/9485279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# (1)  Numpy 텐서플로우 XOR 뉴럴네트워크 \n",
    "    \n",
    "<p> &nbsp;\n",
    "\n",
    "\n",
    "## XOR 문제 : 1969년 패펄트와 민스키\n",
    "\n",
    "### 이 문제가 일으킨 인공지능 겨울과 거북이 LOGO 언어\n",
    "\n",
    "\n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# numpy 행렬 만들기와 텐서플로우 그래프와 변수\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "### 참고자료 :  https://medium.com/ai-india/hello-world-tensorflow-6ce3f5bcbb6b\n",
    "\n",
    "<p> 텐서플로우는 그래프 위에 변수를 연결하고 나중에 sess.run 시킨다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "    \n",
    "### placeholder\n",
    "\n",
    "생성될 때 값을 가지지 않고, 자리(place)를 유지(hold)하는 개념입니다. 함수 f(x)의 x\n",
    "\n",
    "placeholder(\n",
    "    dtype,\n",
    "    shape=None,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "dtype : 데이터 타입을 의미하며 반드시 적어주어야 한다.\n",
    "\n",
    "shape : 입력 데이터의 형태를 의미한다. 상수 값이 될 수도 있고 다차원 배열의 정보가 들어올 수도 있다. \n",
    "( 디폴트 파라미터로 None 지정 )\n",
    "\n",
    "name : 해당 placeholder의 이름을 부여하는 것으로 적지 않아도 된다.  ( 디폴트 파라미터로 None 지정 )\n",
    "\n",
    "### variable\n",
    "\n",
    "생성될때 값을 갖는 상수와 같은 것 (일차함수 ax+b 의  기울기 및 절편과 같은 것)\n",
    "\n",
    "### constant \n",
    "\n",
    "콘스탄트 (잔짜 상수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]]\n",
      "tf.Tensor([[1. 1.]], shape=(1, 2), dtype=float32)\n",
      "(4, 1)\n",
      "(1, 4) ===:=== (4, 2)\n",
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0],\n",
    "                  [0],\n",
    "                  [0],\n",
    "                  [1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "print( y_data.T.dot( x_data   ))\n",
    "\n",
    "print( tf.matmul(  y_data.T , x_data )  )\n",
    "\n",
    "print( y_data.shape )\n",
    "\n",
    "print( y_data.T.shape , '===:===' , x_data.shape )\n",
    "\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "# print(sess.run(a+b))\n",
    "print( a+ b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [[1. 1.]]\n",
    "    tf.Tensor([[1. 1.]], shape=(1, 2), dtype=float32)\n",
    "    (4, 1)\n",
    "    (1, 4) ===:=== (4, 2)\n",
    "    tf.Tensor(42, shape=(), dtype=int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel 메뉴의 restart 하면 새로 시작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.disable_eager_execution()\n",
    "############################\n",
    "\n",
    "c = tf.constant(10)\n",
    "d = tf.constant(32)\n",
    "# print(sess.run(a+b))\n",
    "print( c+d  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.disable_eager_execution() 하면 sess로 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "Tensor(\"Const_2:0\", shape=(), dtype=string)\n",
      "42\n",
      "Tensor(\"add_2:0\", shape=(), dtype=int32)\n",
      "[[1. 1.]]\n",
      "Tensor(\"MatMul_1:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "###################################\n",
    "# initialize the variables\n",
    "# init = tf.global_variables_initializer()\n",
    "# sess.run(init)\n",
    "####################################\n",
    "\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "\n",
    "e = tf.constant(10)\n",
    "f = tf.constant(32)\n",
    "\n",
    "sess = tf.Session()\n",
    "###################\n",
    "\n",
    "\n",
    "print(  sess.run(hello)  )\n",
    "print(  hello )\n",
    "\n",
    "print( sess.run( e+f))\n",
    "print( e+f )\n",
    "\n",
    "print( sess.run( tf.matmul(  y_data.T , x_data ) )  )\n",
    "print( tf.matmul(  y_data.T , x_data ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "Tensor(\"add_6:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant(10)\n",
    "B = tf.constant(32)\n",
    "print(sess.run(A+B))\n",
    "print( A+ B )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 그래프를 먼저 만들고 sess.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()\n",
    "# 텐서플로우 2.0 을 1.* 버젼으로 \n",
    "# 텐서플로우 2.0 이상에는 없다는 뜻\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sigmoid_1:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "print( hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 sess.run 시키는 다음 코드를 설명하자\n",
    "\n",
    "### 인터넷 자료를 참고해서, tensorflow 1.* 의 sess.run 이해하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ==>  0.9565638 [[0.81115395]\n",
      " [2.1068997 ]]\n",
      "100  ==>  0.35035843 [[0.79407674]\n",
      " [1.5368994 ]]\n",
      "200  ==>  0.29053283 [[1.2947081]\n",
      " [1.7493114]]\n",
      "\n",
      "Hypothesis:  [[0.06892454]\n",
      " [0.29859096]\n",
      " [0.21271788]\n",
      " [0.6084238 ]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run( init )\n",
    "\n",
    "    for step in range(201):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(step, ' ==> ', sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 실험 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input data\n",
    "X0_data = np.array([\n",
    "# steps   1st     2nd       3rd\n",
    "        [1, 2], [3, 4], [5, 6]  # first batch\n",
    "\n",
    "]) # shape: [batch_size, n_steps, n_inputs]\n",
    "\n",
    "\n",
    "# input data\n",
    "X1_data = np.array([\n",
    "# steps   1st     2nd       3rd\n",
    "       \n",
    "        [7, 8], [9, 10], [11, 12] # second batch\n",
    "       \n",
    "]) # shape: [batch_size, n_steps, n_inputs]\n",
    "\n",
    "\n",
    "# input data\n",
    "X2_data = np.array([\n",
    "# steps   1st     2nd       3rd\n",
    "     \n",
    "        [13, 14], [15, 16], [17, 18]  # third batch\n",
    "]) # shape: [batch_size, n_steps, n_inputs]\n",
    "\n",
    "print( X0_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "########################\n",
    "# placeholder 등 그래프 리셋\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# hyparameters\n",
    "n_neurons = 8\n",
    "\n",
    "# parameters\n",
    "n_inputs = 2\n",
    "\n",
    "# build a sequence to sequence rnn model\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs]) \n",
    "# shape = [batch_size, n_inputs]\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X2 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal([n_inputs, n_neurons]))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons]))\n",
    "Wy = tf.Variable(tf.random_normal([n_neurons, n_neurons]))\n",
    "\n",
    "y0 = tf.tanh(tf.matmul(X0, Wx) + b) # shape: [batch_size, n_neurons]\n",
    "y1 = tf.tanh(tf.matmul(y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "y2 = tf.tanh(tf.matmul(y1, Wy) + tf.matmul(X2, Wx) + b) \n",
    "\n",
    "output0 = tf.layers.dense(y0, 1) # shape: [batch_size, 1]\n",
    "output1 = tf.layers.dense(y1, 1)\n",
    "output2 = tf.layers.dense(y2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2) (2, 8)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print( X0.shape , sess.run( Wx ).shape )\n",
    "  \n",
    "# error ==> print( sess.run(y0) )\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1033518   1.894466    0.21723342 -0.2838638  -0.26799393  0.1850022\n",
      "   1.4340408  -0.16215995]\n",
      " [ 2.3059587  -1.5268459   1.089537    0.6380484   0.7431295   0.22632456\n",
      "  -1.20283    -0.99043286]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "input0: [1 2] input1: [7 8] input2: [13 14] -> output0: [1.6219375] output1: [1.9967858] output2: [-2.2114635]\n",
      "input0: [3 4] input1: [ 9 10] input2: [15 16] -> output0: [1.9489138] output1: [2.0550857] output2: [-2.4629643]\n",
      "input0: [5 6] input1: [11 12] input2: [17 18] -> output0: [2.2113154] output1: [2.1107101] output2: [-2.795022]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print( sess.run(Wx) )\n",
    "    print( sess.run(b) )\n",
    "    \n",
    "    eval = sess.run(output0, feed_dict={X0: X0_data, X1: X1_data, X2:X2_data})\n",
    "    output1_eval = sess.run(output1, feed_dict={X0: X0_data, X1: X1_data, X2:X2_data})\n",
    "    output2_eval = sess.run(output2, feed_dict={X0: X0_data, X1: X1_data, X2:X2_data})\n",
    "    \n",
    "    print('input0: {} input1: {} input2: {} -> output0: {} output1: {} output2: {}'.format(\n",
    "        X0_data[0], X1_data[0], X2_data[0], output0_eval[0], output1_eval[0], output2_eval[0]))\n",
    "    \n",
    "    print('input0: {} input1: {} input2: {} -> output0: {} output1: {} output2: {}'.format(\n",
    "        X0_data[1], X1_data[1], X2_data[1], output0_eval[1], output1_eval[1], output2_eval[1]))\n",
    "    \n",
    "    print('input0: {} input1: {} input2: {} -> output0: {} output1: {} output2: {}'.format(\n",
    "        X0_data[2], X1_data[2], X2_data[2], output0_eval[2], output1_eval[2], output2_eval[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> &nbsp;\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++\n",
    "<p>\n",
    "\n",
    "# (2) 텐서플로우 CNN 신경망 (mnist 데이터) \n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/mnistcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/mnistcnnani.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very likely that the images in tensorflow.examples.tutorials.mnist have been normalized to the range [0, 1] and therefore you obtain better results. Whereas, the values in MNIST dataset in Keras are in the range [0, 255] and you are expected to normalize them (if needed, of course). Try this:\n",
    "\n",
    "To use this with Keras, we make a dataset out of elements of the form (input batch, output batch). From there, we create a one-shot iterator and a graph node corresponding to its get_next() method. Its components are then provided to the network's Input layer and the Model.compile() method, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 학습을 위한 공개 데이터\n",
    "\n",
    "#### 1. data_in 디렉토리에 iris 데이터를 넣고 pandas 로  불러오기\n",
    "#### 2. from sklearn.datasets import load_iris 로 불러오기\n",
    "#### 3. import tensorflow_datasets as tfds  해서 tfds.load 사용\n",
    "#### 4. from keras.datasets import mnist, cifar10, reuters, imdb 등\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      " 150  27   0   0   0   0   0   0   0   0]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "5\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      "  0.5882353  0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Tensor(\"strided_slice:0\", shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "buffer_size = 10000\n",
    "steps_per_epoch = int(np.ceil(60000 / float(batch_size)))  # = 469\n",
    "epochs = 3 # 5\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "data_train, data_test = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "\n",
    "# Parse images and labels\n",
    "(images_train, labels_train) = data_train\n",
    "(images_test, labels_test) = data_test\n",
    "print( images_train[0][15] )\n",
    "images_train = images_train.astype( np.float32 ) / 255.0\n",
    "# (60000, 28, 28)\n",
    "print( images_train[0][15] )\n",
    "print( labels_train[0] )\n",
    "\n",
    "images_train = np.expand_dims(images_train, -1)\n",
    "labels_train = tf.one_hot(labels_train, num_classes )\n",
    "\n",
    "print( images_train[0][15].T )\n",
    "print( labels_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((28, 28, 1), (10,)), types: (tf.float32, tf.float32)>\n",
      "WARNING:tensorflow:From <ipython-input-3-84f7ea866814>:9: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "(None, 28, 28, 1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((images_train, labels_train))\n",
    "\n",
    "print( dataset ) \n",
    "\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Model creation using tensors from the get_next() graph node.\n",
    "\n",
    "inputs, targets = iterator.get_next()\n",
    "\n",
    "print( inputs.shape )\n",
    "print( targets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "x_train_out (Dense)          (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 843,658\n",
      "Trainable params: 843,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def cnn_layers(inputs):\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu', padding='valid')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_classes,\n",
    "                               activation='softmax',\n",
    "                               name='x_train_out')(x)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "model_input = layers.Input(tensor=inputs)\n",
    "\n",
    "model_output = cnn_layers(model_input)\n",
    "######################################\n",
    "\n",
    "train_model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "train_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'],\n",
    "                    target_tensors=[targets])\n",
    "\n",
    "\n",
    "train_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.1588 - accuracy: 0.9512\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.0511 - accuracy: 0.98480s - loss: 0.0511 - accuracy\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0369 - accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_model.fit(epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "# Save the model weights.\n",
    "\n",
    "weight_path = './data_out/mnist_wt.h5'\n",
    "train_model.save_weights(weight_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Epoch 1/3\n",
    "    469/469 [==============================] - 49s 105ms/step - loss: 0.1588 - accuracy: 0.9512\n",
    "    Epoch 2/3\n",
    "    469/469 [==============================] - 46s 97ms/step - loss: 0.0511 - accuracy: 0.98480s - loss: 0.0511 - accuracy\n",
    "    Epoch 3/3\n",
    "    469/469 [==============================] - 46s 98ms/step - loss: 0.0369 - accuracy: 0.9885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting to reset tensorflow graph \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print( sess.run(...) )\n",
    "    \n",
    "    \n",
    "### when using keras\n",
    "\n",
    "    from keras import backend as K\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 330us/step\n",
      "\n",
      "Test accuracy: 0.9850999712944031\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean up the TF session.\n",
    "K.clear_session()\n",
    "\n",
    "# Second session to test loading trained model without tensors.\n",
    "#(images_test, labels_test) = data_test\n",
    "\n",
    "images_test = images_test.astype(np.float32)\n",
    "images_test = np.expand_dims(images_test, -1)\n",
    "\n",
    "images_test_inp = layers.Input(shape=images_test.shape[1:])\n",
    "\n",
    "labels_out = cnn_layers(images_test_inp)\n",
    "########################################\n",
    "\n",
    "test_model = keras.models.Model(inputs=images_test_inp, outputs=labels_out)\n",
    "\n",
    "test_model.load_weights(weight_path)\n",
    "#####################################\n",
    "\n",
    "test_model.compile(optimizer='rmsprop',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# test_model.summary()\n",
    "\n",
    "#(images_test, labels_test) = data_test\n",
    "loss, acc = test_model.evaluate(images_test, labels_test, num_classes)\n",
    "\n",
    "print('\\nTest accuracy: {0}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10000/10000 [==============================] - 3s 330us/step\n",
    "\n",
    "\n",
    "Test accuracy: 0.9850999712944031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++\n",
    "    \n",
    "<p> &nbsp;\n",
    "\n",
    "# (3) 텐서플로우 케라스를 활용한 자연어 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "example = 'This is a short sentence (1) with one reference to an image. This next sentence, while non-sensical, does not have an image and has two commas.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 6, 7, 2, 8, 9, 10, 11, 12, 3, 4, 1, 13, 2, 14, 15, 16, 17, 18, 19, 3, 4, 20, 21, 22, 23]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this is a short sentence 1 with one reference to an image this next sentence while non sensical does not have an image and has two commas'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer.fit_on_texts([example])\n",
    "\n",
    "s = tokenizer.texts_to_sequences([example])[0]\n",
    "##############################################\n",
    "\n",
    "print(s)\n",
    "\n",
    "' '.join(tokenizer.index_word[i] for i in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes all the punctuation and now we have a random number in the sentence. If we choose to not remove the punctuation, the sentence looks better, but then we have some interesting words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a short sentence (1) with one reference to an image. this next sentence, while non-sensical, does not have an image and has two commas.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['this', 'an', 'is', 'a', 'short', 'sentence', '(1)', 'with', 'one', 'reference', 'to', 'image.', 'next', 'sentence,', 'while', 'non-sensical,', 'does', 'not', 'have', 'image', 'and', 'has', 'two', 'commas.'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer(filters='\"#$%&*+/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer.fit_on_texts([example])\n",
    "\n",
    "s = tokenizer.texts_to_sequences([example])[0]\n",
    "\n",
    "print( ' '.join(tokenizer.index_word[i] for i in s)  )\n",
    "\n",
    "tokenizer.word_index.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that image and image. are classified as distinct words. This is because the period is attached to one and not the other and the same with sentence and sentence,. To alleviate this issue, we can add spaces around the punctuation using regular expressions. We will also remove the image references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a short sentence with one reference to an image . This next sentence , while non-sensical , does not have an image and has two commas .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def format_patent(patent):\n",
    "    \"\"\"Add spaces around punctuation and remove references to images/citations.\"\"\"\n",
    "\n",
    "    # Add spaces around punctuation\n",
    "    patent = re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', patent)\n",
    "\n",
    "    # Remove references to figures\n",
    "    patent = re.sub(r'\\((\\d+)\\)', r'', patent)\n",
    "\n",
    "    # Remove double spaces\n",
    "    patent = re.sub(r'\\s\\s', ' ', patent)\n",
    "    return patent\n",
    "\n",
    "\n",
    "f = format_patent(example)\n",
    "print( f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a short sentence with one reference to an image . this next sentence , while non-sensical , does not have an image and has two commas .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['this', 'sentence', 'an', 'image', '.', ',', 'is', 'a', 'short', 'with', 'one', 'reference', 'to', 'next', 'while', 'non-sensical', 'does', 'not', 'have', 'and', 'has', 'two', 'commas'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer(filters='\"#$%&*+/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts([f])\n",
    "s = tokenizer.texts_to_sequences([f])[0]\n",
    "print( ' '.join(tokenizer.index_word[i] for i in s)  )\n",
    "tokenizer.word_index.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer have the image and image. problem but we do have separate symbols for . and ,. This means the network will be forced to learn a representation for these punctuation marks (they are also in the pre-trained embeddings). When we want to get back to the original sentence (without image references) we simply have to remove the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 ==>  [[1], [0], [1], [1], [0], [1]]\n"
     ]
    }
   ],
   "source": [
    "samples = ['너 오늘 이뻐 보인다', \n",
    "           '나는 오늘 기분이 더러워', \n",
    "           '끝내주는데, 좋은 일이 있나봐', \n",
    "           '나 좋은 일이 생겼어', \n",
    "           '아 오늘 진짜 짜증나', \n",
    "           '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "labels = [[1], [0], [1], [1], [0], [1]]\n",
    "\n",
    "print(  \"라벨 ==> \", labels )\n",
    "\n",
    "# 1 은 긍정적인 문장, 0 은 부정적인 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 단어에 대응되는 숫자 인덱스 : \n",
      " {'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( '각 단어에 대응되는 숫자 인덱스 : \\n' , word_index )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치화된 text data : \n",
      " [[4, 1, 5, 6], [7, 1, 8, 9], [10, 2, 3, 11], [12, 2, 3, 13], [14, 1, 15, 16], [17, 18, 19, 20]]\n",
      "첫번째 문장 :  너 오늘 이뻐 보인다 \n",
      " 변환된 벡터모양 :  [4, 1, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print( '수치화된 text data : \\n' , sequences )\n",
    "\n",
    "print( '첫번째 문장 : ', samples[0],  '\\n 변환된 벡터모양 : ', sequences[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel 메뉴 후, restart 하면 아래 명령에서 에러\n",
    "\n",
    "### tf.disable_eager_execution()  없으면 RuntimeError: \n",
    "\n",
    "The Session graph is empty.  Add operations to the graph before calling run().\n",
    "\n",
    "### 그래서,  tf.disable_eager_execution() 하고 next_data\n",
    "### print( sess.run( next_data )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4, 1, 5, 6]), array([1]))\n",
      "(array([7, 1, 8, 9]), array([0]))\n",
      "(array([10,  2,  3, 11]), array([1]))\n",
      "(array([12,  2,  3, 13]), array([1]))\n",
      "(array([14,  1, 15, 16]), array([0]))\n",
      "(array([17, 18, 19, 20]), array([1]))\n"
     ]
    }
   ],
   "source": [
    "tf.disable_eager_execution()\n",
    "############################\n",
    "\n",
    "\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print( sess.run( next_data ))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x': array([[4, 1, 5, 6],\n",
      "       [7, 1, 8, 9]])}, array([[1],\n",
      "       [0]]))\n",
      "({'x': array([[10,  2,  3, 11],\n",
      "       [12,  2,  3, 13]])}, array([[1],\n",
      "       [1]]))\n",
      "({'x': array([[17, 18, 19, 20],\n",
      "       [14,  1, 15, 16]])}, array([[1],\n",
      "       [0]]))\n",
      "({'x': array([[10,  2,  3, 11],\n",
      "       [ 4,  1,  5,  6]])}, array([[1],\n",
      "       [1]]))\n",
      "({'x': array([[17, 18, 19, 20],\n",
      "       [14,  1, 15, 16]])}, array([[1],\n",
      "       [0]]))\n",
      "({'x': array([[ 7,  1,  8,  9],\n",
      "       [12,  2,  3, 13]])}, array([[0],\n",
      "       [1]]))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "EPOCH = 2\n",
    "\n",
    "def mapping_fn(X, Y=None):\n",
    "    input = {'x': X}\n",
    "    label = Y\n",
    "    return input, label\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "dataset = dataset.map(mapping_fn)\n",
    "dataset = dataset.shuffle(len(sequences))\n",
    "dataset = dataset.batch(BATCH_SIZE) \n",
    "dataset = dataset.repeat(EPOCH)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_data = iterator.get_next()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_data))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator 와 model_fn 만들기\n",
    "\n",
    "### 앞에서의 samples = ['너 오늘 이뻐 보인다', ... 데이터와\n",
    "\n",
    "### tokenizer = preprocessing.text.Tokenizer() 등등 기반으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "    dataset = dataset.repeat(EPOCH)\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.shuffle(len(sequences))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_index) +1\n",
    "\n",
    "EMB_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    embed_input = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE)(features)\n",
    "    embed_input = tf.reduce_mean(embed_input, axis=-1)\n",
    "    \n",
    "    hidden_layer = tf.keras.layers.Dense(128, activation=tf.nn.relu)(embed_input)\n",
    "    output_layer = tf.keras.layers.Dense(1)(hidden_layer)\n",
    "    output = tf.nn.sigmoid(output_layer)\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(output, labels)\n",
    "\n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  train_op=train_op,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './data_out/checkpoint/dnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E63DA00FD0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator = tf.estimator.Estimator( model_fn = model_fn, \n",
    "                                    model_dir = DATA_OUT_PATH + 'checkpoint/dnn')\n",
    "\n",
    "#  ./data_out/checkpoint/dnn\\model.ckpt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimator 로 모델을 train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./data_out/checkpoint/dnn\\model.ckpt-3600\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into ./data_out/checkpoint/dnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5.974564e-07, step = 3600\n",
      "INFO:tensorflow:global_step/sec: 646.88\n",
      "INFO:tensorflow:loss = 2.077689e-06, step = 3700 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 1302.18\n",
      "INFO:tensorflow:loss = 1.0731483e-06, step = 3800 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1354.98\n",
      "INFO:tensorflow:loss = 4.6122477e-07, step = 3900 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1354.96\n",
      "INFO:tensorflow:loss = 1.6259365e-06, step = 4000 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1336.9\n",
      "INFO:tensorflow:loss = 3.911646e-07, step = 4100 (0.074 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4200 into ./data_out/checkpoint/dnn\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 3.870747e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1e63d956dd8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강의에서 다룰 한글 챗봇 데이터에 적용 \n",
    "\n",
    "\n",
    "## data_in/ChatBotData.csv\n",
    "\n",
    "\n",
    "## data_nmt/conversation2.csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2.SK-Konlpy-Matplotlib.ipynb 및 3 및 4 ipynb 참고 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_IN_PATH = './data_in/'\n",
    "\n",
    "data = pd.read_csv(DATA_IN_PATH + 'ChatBotData.csv', encoding='utf-8')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어떻게 지내세요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>잘 지내고 있어요. 당신은요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저도 잘 지내고 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 그럼 안녕히 가세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>계속 연락해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>그러게요. 거긴 어때요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>매우 포근한 날씨네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>나들이 가기 좋은 날씨죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>안녕하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>안녕하세요. 만나서 반가워요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "0           어떻게 지내세요?\n",
       "1    잘 지내고 있어요. 당신은요?\n",
       "2       저도 잘 지내고 있어요.\n",
       "3      네, 그럼 안녕히 가세요.\n",
       "4            계속 연락해요.\n",
       "..                ...\n",
       "495     그러게요. 거긴 어때요?\n",
       "496      매우 포근한 날씨네요.\n",
       "497    나들이 가기 좋은 날씨죠.\n",
       "498             안녕하세요\n",
       "499  안녕하세요. 만나서 반가워요.\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_IN_PATH = './data_nmt/'\n",
    "\n",
    "data = pd.read_csv(DATA_IN_PATH + 'conversation2.csv', encoding='utf-8')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## (1) Numpy 코딩은 스틱 운전 (컨트롤을 매뉴얼하게 할 수 있다)\n",
    "\n",
    "## (2) Estimator 등 사용하는 것은 오토메틱 운전 (not 매뉴얼)\n",
    "<p>\n",
    "\n",
    "# ===================================\n",
    "    \n",
    " \n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++\n",
    "    \n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4)  아기 Baby RNN   Examples\n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input data\n",
    "X_data = np.array([\n",
    "# steps   1st     2nd       3rd\n",
    "        [[1, 2], [7, 8], [13, 14]],  # first batch\n",
    "        [[3, 4], [9, 10], [15, 16]], # second batch\n",
    "        [[5, 6], [11, 12], [17, 18]] # third batch\n",
    "]) # shape: [batch_size, n_steps, n_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-d39e049af304>:16: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-d39e049af304>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# 이 것이 있어야 에러가 안난다.\n",
    "##############################\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "n_neurons = 8\n",
    "\n",
    "# parameters\n",
    "n_inputs = X_data.shape[2]\n",
    "n_steps = X_data.shape[1]\n",
    "\n",
    "# rnn model\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape [batch_size, n_steps, n_neurons]:  [3 3 8]\n",
      "state shape [batch_size, n_neurons]:  [3 8]\n"
     ]
    }
   ],
   "source": [
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {X: X_data}\n",
    "    output_shape = sess.run(tf.shape(output), feed_dict=feed_dict)\n",
    "    state_shape = sess.run(tf.shape(state), feed_dict=feed_dict)\n",
    "    print('output shape [batch_size, n_steps, n_neurons]: ', output_shape)\n",
    "    print('state shape [batch_size, n_neurons]: ', state_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array([\n",
    "# steps   1st     2nd       3rd\n",
    "        [[1, 2], [7, 8], [13, 14]],  # first batch\n",
    "        [[3, 4], [9, 10], [15, 16]], # second batch\n",
    "        [[5, 6], [11, 12], [17, 18]] # third batch\n",
    "]) # shape: [batch_size, n_steps, n_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-8cfe19a56c82>:15: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# hyperparameters\n",
    "n_neurons = 8\n",
    "\n",
    "# parameters\n",
    "n_steps = X_data.shape[1]\n",
    "n_inputs = X_data.shape[2]\n",
    "n_layers = 5 # 5 hidden layers\n",
    "\n",
    "# rnn model\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons) for _ in range(n_layers)]\n",
    "multi_rnn = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "output, state = tf.nn.dynamic_rnn(multi_rnn, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape [batch_size, n_steps, n_neurons]:  [3 3 8]\n",
      "state shape [n_layers, batch_size, n_neurons]:  [5 3 8]\n"
     ]
    }
   ],
   "source": [
    "# initializer the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {X: X_data}\n",
    "    output_shape = sess.run(tf.shape(output), feed_dict=feed_dict)\n",
    "    state_shape = sess.run(tf.shape(state), feed_dict=feed_dict)\n",
    "    print('output shape [batch_size, n_steps, n_neurons]: ', output_shape)\n",
    "    print('state shape [n_layers, batch_size, n_neurons]: ' ,state_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++\n",
    "<p>\n",
    "\n",
    "# (5) RNN + CNN 텍스트 분석 익히기\n",
    "    \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.datasets.imdb.load_data   == IMDB, MNIST 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "(x_train0, y_train), (x_test0, y_test) = tf.keras.datasets.imdb.load_data(path='imdb.npz', num_words=5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16]\n",
      "[1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n",
      "    2    8    4  107  117    2   15  256    4    2    7 3766    5  723\n",
      "   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n",
      "  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n",
      "    2   18    4  226   22   21  134  476   26  480    5  144   30    2\n",
      "   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n",
      "   88   12   16  283    5   16 4472  113  103   32   15   16    2   19\n",
      "  178   32]\n",
      "[1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print( x_train0.shape )  ==>  (25000, )\n",
    "print( x_train0[0][0:200] )\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train0, maxlen=100)\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test0, maxlen=100)\n",
    "\n",
    "# print( x_train.shape) ==> (25000, 100)\n",
    "print( x_train[0] )\n",
    "\n",
    "print( y_train[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         500000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 55)                26400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 56        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 558,520\n",
      "Trainable params: 558,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 25s 995us/step - loss: 0.4543 - accuracy: 0.7654 - val_loss: 0.3402 - val_accuracy: 0.8514\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 25s 986us/step - loss: 0.2916 - accuracy: 0.8784 - val_loss: 0.3280 - val_accuracy: 0.8577\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.2489 - accuracy: 0.8989 - val_loss: 0.3321 - val_accuracy: 0.8572\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.2104 - accuracy: 0.9186 - val_loss: 0.3377 - val_accuracy: 0.8584\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.1774 - accuracy: 0.9314 - val_loss: 0.3558 - val_accuracy: 0.8532\n",
      "25000/25000 [==============================] - 5s 215us/step\n",
      "\n",
      " Test Accuracy: 0.8532\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# seed 값 설정\n",
    "\n",
    "seed = 0\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# 1.* === tf.set_random_seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "# 학습셋과 테스트셋 지정하기\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 전처리\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "\n",
    "\n",
    "\n",
    "# 모델의 설정\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(5000, 100))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "model.add(LSTM(55))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# 모델의 컴파일\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer='adam',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# 모델의 실행\n",
    "\n",
    "history = model.fit( x_train, y_train, batch_size=100, epochs=5,\n",
    "                     validation_data=(x_test, y_test)  )\n",
    "\n",
    "\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "\n",
    "print( \"\\n Test Accuracy: %.4f\" % (model.evaluate(x_test, y_test)[1] )  )\n",
    "\n",
    "\n",
    "\n",
    "# 테스트셋의 오차\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "# 학습셋의 오차\n",
    "\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "\n",
    "\n",
    "# 그래프로 표현\n",
    "\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==================================\n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  [목표] 덧셈 인공지능 여러 코드를 설명하여라\n",
    "\n",
    "## 1. 넘파이 numpy 방법\n",
    "\n",
    "## 2. 텐서플로우 방법\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (목표) 덧셈 인공지능 만들기를 학습하고 설명한다 !!\n",
    "\n",
    "\n",
    "# ====================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# 순환신경망 (Recurrent Neural Network) 사용한다\n",
    "\n",
    "\n",
    "# 방법 1 : 파트 A : 넘파이 버젼\n",
    "\n",
    "# 방법 2 : 파트 B : 텐서플로우 버젼!\n",
    "\n",
    "\n",
    "\n",
    "# Part A - B 코드로 파이썬을 익힌다 !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "# [문제] 아래 코드의 뜻을 스토리텔링 !!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 방법 1 : 파트 A: Numpy 버젼\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## numpy 와 matplot 라이브러리 부르기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임의의 두 수를 만드는 Data Generation\n",
    "\n",
    "Generate the binary array less than 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_DIM = 8\n",
    "INPUT_DIM = 2\n",
    "HIDDEN_DIM = 16\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "ALPHA = 0.1\n",
    "ITER_NUM = 20000\n",
    "LOG_ITER = ITER_NUM // 10\n",
    "PLOT_ITER = ITER_NUM // 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 1 1 ... 1 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "largest = pow(2, BIN_DIM)\n",
    "\n",
    "decimal = np.array([range(largest)]).astype(np.uint8).T\n",
    "\n",
    "binary = np.unpackbits(decimal, axis=1)\n",
    "\n",
    "#print(decimal) ==> 무엇이 될까 ?\n",
    "\n",
    "print(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파트 A : 넘파이로 만드는 덧셈 AI\n",
    "\n",
    "\n",
    "###    Numpy implementation of binary addition in RNN.\n",
    "\n",
    "    https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각각의 두 수에 덧셈값을 대응시키는 model 만들기\n",
    "\n",
    "Prepare weight and delta values to use in the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "[-1.43712545 -1.70632221  0.70443425  2.12440819  4.074456    0.55187473\n",
      "  1.36332517  1.58039568  3.83881483 -0.93203515 -1.70917142 -3.56366082\n",
      "  0.00887929 -0.94196886  1.48419461  3.4086354 ]\n"
     ]
    }
   ],
   "source": [
    "# weight values\n",
    "\n",
    "w0 = np.random.normal(0, 1, [INPUT_DIM, HIDDEN_DIM])\n",
    "\n",
    "w1 = np.random.normal(0, 1, [HIDDEN_DIM, OUTPUT_DIM])\n",
    "\n",
    "wh = np.random.normal(0, 2, [HIDDEN_DIM, HIDDEN_DIM])\n",
    "\n",
    "print( wh.shape )\n",
    "print(wh[0]) # 무엇 ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 바로 위의 행렬을 얻는 것이 목표 (모델)\n",
    "\n",
    "## 처음에는 random 잡고, 학습을 시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n"
     ]
    }
   ],
   "source": [
    "# delta values\n",
    "\n",
    "d0 = np.zeros_like(w0)\n",
    "\n",
    "d1 = np.zeros_like(w1)\n",
    "\n",
    "dh = np.zeros_like(wh)\n",
    "\n",
    "print( dh.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = list()\n",
    "\n",
    "accs = list()\n",
    "\n",
    "error = 0\n",
    "\n",
    "accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습평가용 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def deriv_sigmoid(out):\n",
    "    return out * (1 - out)\n",
    "\n",
    "\n",
    "def bin2dec(b):\n",
    "    out = 0\n",
    "    for i, x in enumerate(b[::-1]):\n",
    "        out += x * pow(2, i)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 위: 에러를 줄이는데 쓰는 함수\n",
    "\n",
    "# 아래: 모델 행렬 최적화하기 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 (Training)\n",
    "\n",
    "Training binary addition in RNN with Backpropagation Through Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Error : [5.01646021]\n",
      "Pred : [0 0 0 0 0 0 0 0]\n",
      "True : [1 1 0 1 1 1 0 1]\n",
      "105 + 116 = 0\n",
      "----------\n",
      "Iter 2000\n",
      "Error : [2.88604484]\n",
      "Pred : [1 0 1 0 1 0 1 0]\n",
      "True : [1 0 1 0 1 0 1 0]\n",
      "103 + 67 = 170\n",
      "----------\n",
      "Iter 4000\n",
      "Error : [1.59448001]\n",
      "Pred : [0 1 1 0 1 1 1 1]\n",
      "True : [0 1 1 0 1 1 1 1]\n",
      "26 + 85 = 111\n",
      "----------\n",
      "Iter 6000\n",
      "Error : [0.47319317]\n",
      "Pred : [0 1 1 1 0 1 0 0]\n",
      "True : [0 1 1 1 0 1 0 0]\n",
      "60 + 56 = 116\n",
      "----------\n",
      "Iter 8000\n",
      "Error : [0.37302183]\n",
      "Pred : [1 0 0 1 1 0 1 1]\n",
      "True : [1 0 0 1 1 0 1 1]\n",
      "87 + 68 = 155\n",
      "----------\n",
      "Iter 10000\n",
      "Error : [0.28312419]\n",
      "Pred : [1 1 0 0 0 1 0 1]\n",
      "True : [1 1 0 0 0 1 0 1]\n",
      "115 + 82 = 197\n",
      "----------\n",
      "Iter 12000\n",
      "Error : [0.34119088]\n",
      "Pred : [1 0 1 0 0 1 0 0]\n",
      "True : [1 0 1 0 0 1 0 0]\n",
      "124 + 40 = 164\n",
      "----------\n",
      "Iter 14000\n",
      "Error : [0.23869753]\n",
      "Pred : [1 1 0 1 0 0 0 1]\n",
      "True : [1 1 0 1 0 0 0 1]\n",
      "125 + 84 = 209\n",
      "----------\n",
      "Iter 16000\n",
      "Error : [0.17723566]\n",
      "Pred : [0 1 1 1 0 0 0 1]\n",
      "True : [0 1 1 1 0 0 0 1]\n",
      "92 + 21 = 113\n",
      "----------\n",
      "Iter 18000\n",
      "Error : [0.23323396]\n",
      "Pred : [1 0 0 0 0 0 1 0]\n",
      "True : [1 0 0 0 0 0 1 0]\n",
      "14 + 116 = 130\n",
      "----------\n",
      "Iter 20000\n",
      "Error : [0.16922046]\n",
      "Pred : [0 1 0 1 1 1 0 0]\n",
      "True : [0 1 0 1 1 1 0 0]\n",
      "8 + 84 = 92\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i in range(ITER_NUM + 1):\n",
    "    # 2만번 학습을 한다 \n",
    "    \n",
    "    # 문제 만들기 : a + b = c\n",
    "    a_dec = np.random.randint(largest / 2)\n",
    "    b_dec = np.random.randint(largest / 2)\n",
    "    c_dec = a_dec + b_dec\n",
    "    \n",
    "    \n",
    "    a_bin = binary[a_dec]\n",
    "    b_bin = binary[b_dec]\n",
    "    c_bin = binary[c_dec]\n",
    "    \n",
    "    pred = np.zeros_like(c_bin)\n",
    "    # prediction 답 \n",
    "    \n",
    "    overall_err = 0 \n",
    "    # total error in the whole calculation process.\n",
    "    \n",
    "    output_deltas = list()\n",
    "    hidden_values = list()\n",
    "    hidden_values.append(np.zeros(HIDDEN_DIM))\n",
    "    \n",
    "    future_delta = np.zeros(HIDDEN_DIM)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    # forward propagation\n",
    "    for pos in range(BIN_DIM)[::-1]:\n",
    "        X = np.array([[a_bin[pos], b_bin[pos]]]) # shape=(1, 2)\n",
    "        Y = np.array([[c_bin[pos]]]) # shape=(1, 1)\n",
    "        \n",
    "        hidden = sigmoid(np.dot(X, w0) + np.dot(hidden_values[-1], wh))\n",
    "        output = sigmoid(np.dot(hidden, w1))\n",
    "        \n",
    "        pred[pos] = np.round(output[0][0])\n",
    "        \n",
    "        # squared mean error\n",
    "        output_err = Y - output\n",
    "        output_deltas.append(output_err * deriv_sigmoid(output))\n",
    "        hidden_values.append(hidden)\n",
    "        \n",
    "        overall_err += np.abs(output_err[0])\n",
    "    #########################################################    \n",
    "        \n",
    "    \n",
    "    #########################################################\n",
    "    # backpropagation through time\n",
    "    for pos in range(BIN_DIM):\n",
    "        X = np.array([[a_bin[pos], b_bin[pos]]])\n",
    "        \n",
    "        hidden = hidden_values[-(pos + 1)]\n",
    "        prev_hidden = hidden_values[-(pos + 2)]\n",
    "        \n",
    "        output_delta = output_deltas[-(pos + 1)]\n",
    "        hidden_delta = (np.dot(future_delta, wh.T) + np.dot(output_delta, w1.T)) * deriv_sigmoid(hidden)\n",
    "        \n",
    "        d1 += np.dot(np.atleast_2d(hidden).T, output_delta)\n",
    "        dh += np.dot(np.atleast_2d(prev_hidden).T, hidden_delta)\n",
    "        d0 += np.dot(X.T, hidden_delta)\n",
    "\n",
    "        future_delta = hidden_delta     \n",
    "    ##########################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    w1 += ALPHA * d1\n",
    "    w0 += ALPHA * d0\n",
    "    wh += ALPHA * dh\n",
    "    \n",
    "    \n",
    "    d1 *= 0\n",
    "    d0 *= 0\n",
    "    dh *= 0\n",
    "    \n",
    "    ###################\n",
    "    # 핼렬교정 . 테스트\n",
    "    ###################\n",
    "    \n",
    "    error += overall_err\n",
    "    ### 에러 ###########\n",
    "    \n",
    "    \n",
    "    if (bin2dec(pred) == c_dec):\n",
    "        accuracy += 1\n",
    "        \n",
    "    if (i % PLOT_ITER == 0):\n",
    "        errs.append(error / PLOT_ITER)\n",
    "        accs.append(accuracy / PLOT_ITER)\n",
    "        \n",
    "        error = 0\n",
    "        accuracy = 0\n",
    "    \n",
    "    if (i % LOG_ITER == 0):\n",
    "        print('Iter', i)\n",
    "        print(\"Error :\", overall_err)\n",
    "        print(\"Pred :\", pred)\n",
    "        print(\"True :\", c_bin)\n",
    "        print(a_dec, \"+\", b_dec, \"=\", bin2dec(pred))\n",
    "        print('----------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1994df3ca90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errs, label='error')\n",
    "plt.plot(accs, label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 방법 2 : Part B  : 텐서플로우로 만드는 덧셈 AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 1.0 코딩으로 만드는 덧셈 인공지능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치된 버젼이 2.0 이기에 import tensorflow.compat.v1  as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우와 sklearn 과 넘파이 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow.compat.v1  as tf\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "#RuntimeError: tf.placeholder() is not compatible with eager execution.\n",
    "#import tensorflow as tf\n",
    "\n",
    "#from tensorflow.contrib.rnn import GRUCell\n",
    "from tensorflow.compat.v1.nn import rnn_cell as rnn\n",
    "\n",
    "####################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### inference() , loss() , training()  함수 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def inference(x, y, n_batch, is_training,\n",
    "              input_digits=None, output_digits=None,\n",
    "              n_hidden=None, n_out=None):\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.zeros(shape, dtype=tf.float32)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    # Encoder\n",
    "    encoder = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    state = encoder.zero_state(n_batch, tf.float32)\n",
    "    encoder_outputs = []\n",
    "    encoder_states = []\n",
    "\n",
    "    with tf.variable_scope('Encoder'):\n",
    "        for t in range(input_digits):\n",
    "            if t > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            (output, state) = encoder(x[:, t, :], state)\n",
    "            encoder_outputs.append(output)\n",
    "            encoder_states.append(state)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    state = encoder_states[-1]\n",
    "    decoder_outputs = [encoder_outputs[-1]]\n",
    "\n",
    "    # 출력층의 웨이트와 바이어스를 미리 정의해둔다\n",
    "    V = weight_variable([n_hidden, n_out])\n",
    "    c = bias_variable([n_out])\n",
    "    outputs = []\n",
    "\n",
    "    with tf.variable_scope('Decoder'):\n",
    "        for t in range(1, output_digits):\n",
    "            if t > 1:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            if is_training is True:\n",
    "                (output, state) = decoder(y[:, t-1, :], state)\n",
    "            else:\n",
    "                # 직전의 출력을 입력으로 사용한다\n",
    "                linear = tf.matmul(decoder_outputs[-1], V) + c\n",
    "                out = tf.nn.softmax(linear)\n",
    "                outputs.append(out)\n",
    "                out = tf.one_hot(tf.argmax(out, -1), depth=output_digits)\n",
    "                (output, state) = decoder(out, state)\n",
    "\n",
    "            decoder_outputs.append(output)\n",
    "\n",
    "    if is_training is True:\n",
    "        output = tf.reshape(tf.concat(decoder_outputs, axis=1),\n",
    "                            [-1, output_digits, n_hidden])\n",
    "\n",
    "        linear = tf.einsum('ijk,kl->ijl', output, V) + c\n",
    "        # linear = tf.matmul(output, V) + c\n",
    "        return tf.nn.softmax(linear)\n",
    "    else:\n",
    "        # 마지막 출력을 구한다\n",
    "        linear = tf.matmul(decoder_outputs[-1], V) + c\n",
    "        out = tf.nn.softmax(linear)\n",
    "        outputs.append(out)\n",
    "\n",
    "        output = tf.reshape(tf.concat(outputs, axis=1),\n",
    "                            [-1, output_digits, n_out])\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losss\n",
    "\n",
    "def loss(y, t):\n",
    "    cross_entropy = \\\n",
    "        tf.reduce_mean(-tf.reduce_sum(\n",
    "                       t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)),\n",
    "                       reduction_indices=[1]))\n",
    "    return cross_entropy\n",
    "\n",
    "# training\n",
    "\n",
    "def training(loss):\n",
    "    optimizer = \\\n",
    "        tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "# accuracy\n",
    "\n",
    "\n",
    "def accuracy(y, t):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, -1), tf.argmax(t, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 덧셈 뉴럴네트워크 학습시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "validation loss: 0.60500246  validation acc:  0.350875\n",
      "Q:   56+579  ==  111   T/F:  F\n",
      "----------\n",
      "Epoch: 10\n",
      "validation loss: 0.50476736  validation acc:  0.437375\n",
      "Q:   807+1   ==  881   T/F:  F\n",
      "----------\n",
      "Epoch: 20\n",
      "validation loss: 0.4103484  validation acc:  0.53875\n",
      "Q:   56+450  ==  517   T/F:  F\n",
      "----------\n",
      "Epoch: 30\n",
      "validation loss: 0.34449187  validation acc:  0.611375\n",
      "Q:   766+71  ==  847   T/F:  F\n",
      "----------\n",
      "Epoch: 40\n",
      "validation loss: 0.25000912  validation acc:  0.71175\n",
      "Q:   26+964  ==  990   T/F:  T\n",
      "----------\n",
      "Epoch: 50\n",
      "validation loss: 0.17044547  validation acc:  0.81425\n",
      "Q:   502+1   ==  503   T/F:  T\n",
      "----------\n",
      "Epoch: 60\n",
      "validation loss: 0.12936434  validation acc:  0.860125\n",
      "Q:   780+29  ==  809   T/F:  T\n",
      "----------\n",
      "Epoch: 70\n",
      "validation loss: 0.10709395  validation acc:  0.8855\n",
      "Q:   95+38   ==  133   T/F:  T\n",
      "----------\n",
      "Epoch: 80\n",
      "validation loss: 0.09231016  validation acc:  0.901\n",
      "Q:   8+465   ==  473   T/F:  T\n",
      "----------\n",
      "Epoch: 90\n",
      "validation loss: 0.08404567  validation acc:  0.90775\n",
      "Q:   47+329  ==  376   T/F:  T\n",
      "----------\n",
      "Epoch: 100\n",
      "validation loss: 0.07819431  validation acc:  0.922375\n",
      "Q:   327+261 ==  588   T/F:  T\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "\n",
    "history = {\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    (\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    def n(digits=3):\n",
    "        number = ''\n",
    "        for i in range(np.random.randint(1, digits + 1)):\n",
    "            number += np.random.choice(list('0123456789'))\n",
    "        return int(number)\n",
    "\n",
    "    def padding(chars, maxlen):\n",
    "        return chars + ' ' * (maxlen - len(chars))\n",
    "\n",
    "    '''\n",
    "    데이터를 생성한다\n",
    "    '''\n",
    "    N = 20000\n",
    "    N_train = int(N * 0.9)\n",
    "    N_validation = N - N_train\n",
    "\n",
    "    digits = 3  # 최대 자릿수\n",
    "    input_digits = digits * 2 + 1  # 예： 1234+5678\n",
    "    output_digits = digits + 1  # 500+500 = 1000 이상이면 4자리가 된다\n",
    "\n",
    "    added = set()\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    while len(questions) < N:\n",
    "        a, b = n(), n()  # 두 개의 수를 적당히 생성한다\n",
    "\n",
    "        pair = tuple(sorted((a, b)))\n",
    "        if pair in added:\n",
    "            continue\n",
    "\n",
    "        question = '{}+{}'.format(a, b)\n",
    "        question = padding(question, input_digits)\n",
    "        answer = str(a + b)\n",
    "        answer = padding(answer, output_digits)\n",
    "\n",
    "        added.add(pair)\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "\n",
    "    chars = '0123456789+ '\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "    X = np.zeros((len(questions), input_digits, len(chars)), dtype=np.integer)\n",
    "    Y = np.zeros((len(questions), digits + 1, len(chars)), dtype=np.integer)\n",
    "\n",
    "    for i in range(N):\n",
    "        for t, char in enumerate(questions[i]):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        for t, char in enumerate(answers[i]):\n",
    "            Y[i, t, char_indices[char]] = 1\n",
    "\n",
    "    X_train, X_validation, Y_train, Y_validation = \\\n",
    "        train_test_split(X, Y, train_size=N_train)\n",
    "\n",
    "    '''\n",
    "    모델을 설정한다\n",
    "    '''\n",
    "    n_in = len(chars)  # 12\n",
    "    n_hidden = 128\n",
    "    n_out = len(chars)  # 12\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, input_digits, n_in])\n",
    "    t = tf.placeholder(tf.float32, shape=[None, output_digits, n_out])\n",
    "    n_batch = tf.placeholder(tf.int32, shape=[])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####  inference() , loss() , training()  #######\n",
    "\n",
    "    y = inference(x, t, n_batch, is_training,\n",
    "                  input_digits=input_digits,\n",
    "                  output_digits=output_digits,\n",
    "                  n_hidden=n_hidden, n_out=n_out)\n",
    "    \n",
    "    loss = loss(y, t)\n",
    "    # 다시하면 loss 에러\n",
    "    \n",
    "    train_step = training(loss)\n",
    "    \n",
    "    \n",
    "    acc = accuracy(y, t)\n",
    "    # 평가 \n",
    "    \n",
    "    ##################################################\n",
    "    \n",
    "  \n",
    "    '''\n",
    "    모델을 학습시킨다\n",
    "    '''\n",
    "    epochs = 101 #200\n",
    "    batch_size = 200\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    n_batches = N_train // batch_size\n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            sess.run(train_step, feed_dict={\n",
    "                x: X_[start:end],\n",
    "                t: Y_[start:end],\n",
    "                n_batch: batch_size,\n",
    "                is_training: True\n",
    "            })\n",
    "\n",
    "        # 검증 데이터를 사용해서 평가한다\n",
    "        if epoch%10 ==0 :\n",
    "            \n",
    "            #print('=' * 10)\n",
    "            print('Epoch:', epoch)\n",
    "            #print('=' * 10)\n",
    "\n",
    "\n",
    "            val_loss = loss.eval(session=sess, feed_dict={\n",
    "            x: X_validation,\n",
    "            t: Y_validation,\n",
    "            n_batch: N_validation,\n",
    "            is_training: False\n",
    "                })\n",
    "            \n",
    "            val_acc = acc.eval(session=sess, feed_dict={\n",
    "            x: X_validation,\n",
    "            t: Y_validation,\n",
    "            n_batch: N_validation,\n",
    "            is_training: False\n",
    "                })\n",
    "\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print('validation loss:', val_loss, ' validation acc: ', val_acc)\n",
    "\n",
    "            # 검증 데이터에서 무작위로 문제를 선택해서 답을 맞춘다\n",
    "            # if epoch%10==0 : # or i in range(1):\n",
    "        \n",
    "            index = np.random.randint(0, N_validation)\n",
    "            question = X_validation[np.array([index])]\n",
    "            answer = Y_validation[np.array([index])]\n",
    "            prediction = y.eval(session=sess, feed_dict={\n",
    "                x: question,\n",
    "                # t: answer,\n",
    "                n_batch: 1,\n",
    "                is_training: False\n",
    "            })\n",
    "            question = question.argmax(axis=-1)\n",
    "            answer = answer.argmax(axis=-1)\n",
    "            prediction = np.argmax(prediction, -1)\n",
    "\n",
    "            q = ''.join(indices_char[i] for i in question[0])\n",
    "            a = ''.join(indices_char[i] for i in answer[0])\n",
    "            p = ''.join(indices_char[i] for i in prediction[0])\n",
    "\n",
    "            \n",
    "            print('Q:  ', q , '== ', p, ' T/F: ', end=' ')\n",
    "            #print('A:  ', p)\n",
    "            #print('T/F:', end=' ')\n",
    "            if a == p:\n",
    "                print('T')\n",
    "            else:\n",
    "                print('F')\n",
    "                \n",
    "            print('-' * 10 )\n",
    "                \n",
    "        # print('-' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.350875, 0.437375, 0.53875, 0.611375, 0.71175, 0.81425, 0.860125, 0.8855, 0.901, 0.90775, 0.922375]\n"
     ]
    }
   ],
   "source": [
    "print( history['val_acc'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history['val_acc'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history['val_loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "plt.legend(['val_acc', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "# 텐서플로 2.0 버젼으로 바꾸기 ????\n",
    "\n",
    "\n",
    "\n",
    "# +++++++++++++++++++++++++++ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
