{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 탐구실험용 toy 코드  (Facebook 바비 Question-Answer)\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  toy 코드의 한계 및 약점은 ? 약점을 보강할 수 있는 방법 ?\n",
    "\n",
    "<p>\n",
    "\n",
    "# 영어와 한글 데이터의 부족을 한영 번역기로 try 하며 탐구\n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n",
    "## +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "## toy 코드를 통해 약점을 알아내고, 데이터를 조작하며 (좋은 뜻으로 조절),\n",
    "\n",
    "## 데이터가 어떻게 변형되고, 행렬의 weight와 정확도가 어떻게 변화하는지?\n",
    "\n",
    "## input 과 중간의 형태, 그리고 최종 output 의 흐름을 스토리텔링하며 탐구 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========== 탐구과제용 :기본적인 문제 =========\n",
    "\n",
    "# 어떻게 AI 와 수학교육이 융합하여 발전할 수 있을까?\n",
    "\n",
    "# 영어 데이터를 한글 학습데이터를 번역하고 보강한다.\n",
    "\n",
    "# 한국어 질문-응답 수학학습 시스템을 만들 수 있을까?\n",
    "\n",
    "# 무엇보다도, 데이터를 처리하는 방법을 먼저 익히고\n",
    "\n",
    "# 데이터로 딥러닝하는 알고리즘과 attention 을 탐구하자.\n",
    "\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Babi 문제 (인터넷에서 babi 문제와 데이터를 찾아본다)\n",
    "\n",
    "# 교재 130 페이지 참고"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# babi 데이터 \n",
    "\n",
    "    Sandra travelled to the kitchen. \n",
    "    Sandra travelled to the hallway. \n",
    "    Mary went to the bathroom. \n",
    "    Sandra moved to the garden. \n",
    "\n",
    "    Where is Sandra ?\n",
    "    Ground Truth: Garden (based on single supporting fact 4)\n",
    "\n",
    "### Each sentence is provided with an ID. The IDs for a given “story” start at 1 and increase. \n",
    "### When the IDs in a file reset back to 1 you can consider the following sentences as a new “story”. \n",
    "### Supporting fact ID refer to the sentences within a “story”.\n",
    "\n",
    "    1 Mary moved to the bathroom.\n",
    "    2 John went to the hallway.\n",
    "    3 Where is Mary?        bathroom        1\n",
    "    4 Daniel went back to the hallway.\n",
    "    5 Sandra moved to the garden.\n",
    "    6 Where is Daniel?      hallway         4\n",
    "    7 John moved to the office.\n",
    "    8 Sandra journeyed to the bathroom.\n",
    "    9 Where is Daniel?      hallway         4\n",
    "    10 Mary moved to the hallway.\n",
    "    11 Daniel travelled to the office.\n",
    "    12 Where is Daniel?     office          11\n",
    "    13 John went back to the garden.\n",
    "    14 John moved to the bedroom.\n",
    "    15 Where is Sandra?     bathroom        8\n",
    "    1 Sandra travelled to the office.\n",
    "    2 Sandra went to the bathroom.\n",
    "    3 Where is Sandra?      bathroom        2\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 바비 데이터 github  : https://github.com/andri27-ts/bAbI\n",
    "\n",
    "<p>\n",
    "\n",
    "\n",
    "# 수학교육 탐구과제로 도전가능한 문제    \n",
    "    \n",
    "# QA6 - Yes/No Questions\t\n",
    "\n",
    "# QA7 - Counting\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바비 데이터 : https://github.com/harvardnlp/MemN2N/tree/master/babi_data/en\n",
    "\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "    \n",
    "# settings ==> .keras ==> dataset 안에 데이터 저장됨 \n",
    "\n",
    "\n",
    "https://appliedmachinelearning.blog/2019/05/01/developing-factoid-question-answering-system-on-babi-facebook-data-set-python-keras-part-1/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature Extraction\n",
    "\n",
    "Let us first write a helper function to vectorize each stories in order to fetch it to memory network model which we will be creating later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://appliedmachinelearning.blog/2019/05/02/building-end-to-end-memory-network-for-question-answering-system-on-babi-facebook-data-set-python-keras-part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================================\n",
    "\n",
    "\n",
    "# 바비 데이터로 뉴럴네트워크 모델 학습시키기 \n",
    "\n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# === 자연어처리 :  babi  QAchatbot  만들기 ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> &nbsp;\n",
    "\n",
    "# 본래의 Babi QA6 데이터는 data_in 에있다\n",
    "\n",
    "## ./data_in/babi_qa6_train.txt\n",
    "\n",
    "## ./data_in/babi_qa6_test.txt\n",
    "\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# =================================\n",
    "    \n",
    "<p> &nbsp;\n",
    "\n",
    "# toy code 에서는 다음 데이터를 사용한다.\n",
    "\n",
    "## ./data_in/babi_train_qa.txt\n",
    "\n",
    "## ./data_in/babi_test_qa.txt\n",
    "    \n",
    "## toy code 의 데이터와 본래 데이터의 차이점은 ??\n",
    "    \n",
    "## +++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> &nbsp;\n",
    "\n",
    "# ========= Toy 바비 QA 탐구==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickle 데이터 파일과 csv 데이터 파일\n",
    "\n",
    "## 교재 80페이지의 pandas, numpy 를 익힌다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  \\\n",
      "0  [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
      "1  [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
      "2  [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
      "3  [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
      "4  [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
      "\n",
      "                                    1    2  \n",
      "0   [Is, Sandra, in, the, hallway, ?]   no  \n",
      "1  [Is, Daniel, in, the, bathroom, ?]   no  \n",
      "2    [Is, Daniel, in, the, office, ?]   no  \n",
      "3   [Is, Daniel, in, the, bedroom, ?]  yes  \n",
      "4   [Is, Daniel, in, the, bedroom, ?]  yes  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve training data\n",
    "\n",
    "# IOPub data rate exceeded. \n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000\n",
    "\n",
    "unpickled_df = pd.read_pickle('./data_in/babi_train_qa.txt')\n",
    "# print( unpickled_df)== list 이다 \n",
    "   \n",
    "df = pd.DataFrame( unpickled_df )  \n",
    "# df = pd.DataFrame(some_list, columns=[\"colummn\"]) \n",
    "\n",
    "df.to_csv('./data_in/babi_train_qa.csv', index=False)\n",
    "\n",
    "print( df[0:5] ) \n",
    "\n",
    "df.shape # 학습 데이터의 갯수 일만개 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'got', 'the', 'milk', 'there', '.', 'John', 'moved', 'to', 'the', 'bedroom', '.']\n",
      "['Is', 'John', 'in', 'the', 'kitchen', '?']\n",
      "no\n",
      "['Mary', 'got', 'the', 'milk', 'there', '.', 'John', 'moved', 'to', 'the', 'bedroom', '.', 'Mary', 'discarded', 'the', 'milk', '.', 'John', 'went', 'to', 'the', 'garden', '.', 'Daniel', 'moved', 'to', 'the', 'bedroom', '.', 'Daniel', 'went', 'to', 'the', 'garden', '.', 'Daniel', 'travelled', 'to', 'the', 'bathroom', '.', 'Sandra', 'travelled', 'to', 'the', 'bedroom', '.', 'Mary', 'took', 'the', 'football', 'there', '.', 'Sandra', 'grabbed', 'the', 'milk', 'there', '.']\n",
      "['Is', 'Daniel', 'in', 'the', 'bedroom', '?']\n",
      "no\n",
      "['Daniel', 'went', 'back', 'to', 'the', 'kitchen', '.', 'Mary', 'grabbed', 'the', 'apple', 'there', '.']\n",
      "['Is', 'Daniel', 'in', 'the', 'office', '?']\n",
      "no\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "#retrieve training data\n",
    "\n",
    "# IOPub data rate exceeded.\n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000\n",
    "\n",
    "unpickled_df = pd.read_pickle('./data_in/babi_test_qa.txt')\n",
    "# print( unpickled_df)== list 이다 \n",
    "   \n",
    "df = pd.DataFrame( unpickled_df )  \n",
    "# df = pd.DataFrame(some_list, columns=[\"colummn\"]) \n",
    "\n",
    "df.to_csv('./data_in/babi_test_qa.csv', index=False)\n",
    "\n",
    "print( df[0][0] )\n",
    "print( df[1][0] )\n",
    "print( df[2][0] )\n",
    "\n",
    "print( df[0][4] )\n",
    "print( df[1][4] )\n",
    "print( df[2][4] )\n",
    "\n",
    "print( df[0][5] )\n",
    "print( df[1][5] )\n",
    "print( df[2][5] )\n",
    "\n",
    "print( df.shape )  # ===> 테스트 데이터의 갯수 1000 개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# [문제] 아래 QA6 text 파일과 비교하여보라\n",
    "\n",
    "## ./data_in/babi_qa6_train.txt\n",
    "\n",
    "## ./data_in/babi_qa6_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Sandra', 'went', 'back', 'to', 'the', 'hallway', '.', 'Sandra', 'moved', 'to', 'the', 'office', '.'], ['Is', 'Sandra', 'in', 'the', 'office', '?'], 'yes')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data_in/babi_train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "print( train_data[10] )\n",
    "train_data[0][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve test data\n",
    "\n",
    "with open('./data_in/babi_test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of training instances\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of test instances\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sandra',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'office', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of one of the instances\n",
    "\n",
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sandra went back to the hallway . Sandra moved to the office .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the office ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# [과제] 한글 챗복 데이터 다루기    \n",
    "    \n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n",
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p>\n",
    "\n",
    "# [과제 1] data_nmt/conversaiton2.txt  데이터 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어떻게 지내세요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>잘 지내고 있어요. 당신은요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저도 잘 지내고 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 그럼 안녕히 가세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>계속 연락해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>그러게요. 거긴 어때요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>매우 포근한 날씨네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>나들이 가기 좋은 날씨죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>안녕하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>안녕하세요. 만나서 반가워요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "0           어떻게 지내세요?\n",
       "1    잘 지내고 있어요. 당신은요?\n",
       "2       저도 잘 지내고 있어요.\n",
       "3      네, 그럼 안녕히 가세요.\n",
       "4            계속 연락해요.\n",
       "..                ...\n",
       "495     그러게요. 거긴 어때요?\n",
       "496      매우 포근한 날씨네요.\n",
       "497    나들이 가기 좋은 날씨죠.\n",
       "498             안녕하세요\n",
       "499  안녕하세요. 만나서 반가워요.\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = open( \"./data_nmt/conversation2.txt\", \"r\" , encoding=\"utf-8\")\n",
    "data = file.readlines()\n",
    "df1 = []\n",
    "for ii in data:\n",
    "    df1.append(ii[:-1])\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame( df1  )\n",
    " \n",
    "df2.to_csv( './data_nmt/conversation2.csv' , index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "datacsv = pd.read_csv( './data_nmt/conversation2.csv' ,  encoding='utf-8')\n",
    "\n",
    "datacsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "0         어떻게 지내세요?\n",
      "1  잘 지내고 있어요. 당신은요?\n",
      "2     저도 잘 지내고 있어요.\n",
      "3    네, 그럼 안녕히 가세요.\n",
      "4          계속 연락해요.\n",
      "어떻게 지내세요?\n",
      "잘 지내고 있어요. 당신은요?\n",
      "저도 잘 지내고 있어요.\n",
      "네, 그럼 안녕히 가세요.\n",
      "계속 연락해요.\n",
      "['어떻게 지내세요 ?', '잘 지내고있어요 . 당 신 은 요 ?', '저 도 잘 지내고있어요 .', '네 , 그럼 안녕히가세요 .', '계속 연락 해 요 .']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['어떻게 지내세요 ?',\n",
       " '잘 지내고있어요 . 당 신 은 요 ?',\n",
       " '저 도 잘 지내고있어요 .',\n",
       " '네 , 그럼 안녕히가세요 .',\n",
       " '계속 연락 해 요 .']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( datacsv[0:5] )\n",
    "\n",
    "result_data=list( )\n",
    "\n",
    "input_data = list( datacsv['0'][0:5] )\n",
    "######################################\n",
    "\n",
    "for seq in input_data :\n",
    "    print( seq )\n",
    "    result = \" \".join( okt.morphs(seq.replace(' ', '')))\n",
    "    result_data.append( result )\n",
    "    \n",
    "print( result_data )\n",
    "\n",
    "datas = []\n",
    "\n",
    "datas.extend( result_data )\n",
    "             \n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['어떻게', '지내세요', '잘', '지내고있어요', '당', '신', '은', '요', '저', '도', '잘', '지내고있어요', '네', '그럼', '안녕히가세요', '계속', '연락', '해', '요']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "vocabwords = []\n",
    "for sentence in datas:\n",
    "    # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "    # 위 필터와 같은 값들을 정규화 표현식을 \n",
    "    # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "    sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "    for word in sentence.split():\n",
    "        vocabwords.append(word)\n",
    "            \n",
    "print( vocabwords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['스트레스', '캐나다의', '다음에', '볼링이나', '미용실은', '지갑', '4분전에요', '바쿠', '언제', '이메일로']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'어떻게 지내세요?\\n잘 지내고 있어요. 당신은요?\\n저도 잘 지내고 있어요.\\n네, 그럼 안녕히 가세요.\\n계속 연락해요.\\n네, 제가 곧 다시 연락 드릴게요.\\n이메일로 연락주세요.\\n지금 '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "DATA_PATH=\"./data_nmt/conversation2.txt\" \n",
    "############## 챗봇 데이터 ############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Tokenizer( sentence ):\n",
    "    token=[]\n",
    "    for word in sentence.strip().split():\n",
    "        token.extend(re.compile(\"([.,!?\\\"':;)(])\").split(word))\n",
    "        \n",
    "    ret=[t for t in token if t]\n",
    "    return ret             \n",
    "\n",
    "    \n",
    "    \n",
    "wordsk=[]\n",
    "datask=[]\n",
    "\n",
    "\n",
    "\n",
    "with open( DATA_PATH , 'r' , encoding='utf-8' ) as f:\n",
    "    lines=f.read()\n",
    "    datask.append(lines)\n",
    "    wordsk=Tokenizer( lines  )\n",
    "    wordsk=list( set( wordsk ) )\n",
    "\n",
    "    \n",
    "# list <=== datas.shape \n",
    "\n",
    "\n",
    "print( wordsk[0:10] )\n",
    "\n",
    "datask[0][0:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['칠까', '스트레스', '전부터', '의', '지갑', '바쿠', '언제', '레스', '야', '모르는']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 지내고 있어요. 당신은요?\\n저도 잘 지내고 있어요.\\n네, 그럼 안녕히 가세요.\\n계속 연락해요.\\n네, 제가 곧 다시 연락 드릴게요.\\n이메일로 연락주세요.\\n지금 어디신가요?\\n집이요'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "\n",
    "wordsz=[]\n",
    "datasz=[]\n",
    "\n",
    "with open(  DATA_PATH , 'r', encoding='utf-8') as  content_file :\n",
    "    for con in content_file: \n",
    "        content = content_file.read()\n",
    "        datasz.append( content )\n",
    "        wordsz.extend( okt.morphs(content)   )\n",
    "        wordsz = list(set(wordsz))\n",
    "\n",
    "            \n",
    "print( wordsz[0:10] )\n",
    "\n",
    "datasz[0][0:100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p>\n",
    "\n",
    "# [과제 2] data_in/ChatBotData.csv 데이터 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 32/23646 [00:00<01:18, 302.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 23646/23646 [00:58<00:00, 403.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv( './data_in/ChatBotData.csv' , encoding='utf-8')\n",
    "\n",
    "print( data.head()  ) \n",
    "\n",
    "questions, answers  = list( data['Q'] ) , list( data['A'] )\n",
    "\n",
    "\n",
    "from konlpy.tag import Okt # Twitter\n",
    "from tqdm import tqdm\n",
    "   \n",
    "morph_analyzer = Okt()  # Twitter()\n",
    "# 형태소 토크나이즈 결과 문장을 받을\n",
    "#  리스트를 생성합니다.\n",
    "\n",
    "result_data = list()\n",
    "# 데이터에 있는 매 문장에 대해 토크나이즈를\n",
    "# 할 수 있도록 반복문을 선언합니다.\n",
    "\n",
    "\n",
    "# Twitter.morphs 함수를 통해 토크나이즈 된\n",
    "# 리스트 객체를 받고 다시 공백문자를 기준으로\n",
    "# 하여 문자열로 재구성 해줍니다.\n",
    "for seq in tqdm( questions + answers ):\n",
    "    morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n",
    "    result_data.append(morphlized_seq)\n",
    "    \n",
    "    \n",
    "questions = result_data         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111808\n",
      "15680\n",
      "단어장이 새로 만들어짐 !!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "\n",
    "vocabwords = []\n",
    "for sentence in datas:\n",
    "    # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "    # 위 필터와 같은 값들을 정규화 표현식을 \n",
    "    # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "    sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "    for word in sentence.split():\n",
    "        vocabwords.append(word)\n",
    "            \n",
    "\n",
    "print( len(vocabwords)  )\n",
    "            \n",
    "vocab = set( vocabwords )\n",
    "\n",
    "print( len(vocab) )\n",
    "\n",
    "vocfile = './data_out/vocabularyData.txt'\n",
    "\n",
    "with open(vocfile , 'w' , encoding='utf-8') as wf:\n",
    "    for w in vocab:\n",
    "        wf.write(w+\"\\n\")\n",
    "    print(\"단어장이 새로 만들어짐 !!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p>\n",
    "    \n",
    "\n",
    "# [문제] 한글 단어장을 만드는 과정을 이해하자 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "#  챗봇 데이터의 단어장으로 문장을 벡터로 표현 !!\n",
    "    \n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n",
    "# ++++++++++++++++++++++++++++++++++++\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교재 30페이지의 내용과 비교한다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "set1=[1,2,3,4,5, 1,2,3,9]\n",
    "set2=[2,3,5,6,7, 2,3,4,8]\n",
    "\n",
    "set1 = set(set1)  \n",
    "\n",
    "moim = set()\n",
    "\n",
    "moim = moim.union( set1)\n",
    "moim = moim.intersection( set(set2))\n",
    "print( moim  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ./data_in/babi_train_qa.txt  데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Sandra', 'went', 'back', 'to', 'the', 'hallway', '.', 'Sandra', 'moved', 'to', 'the', 'office', '.'], ['Is', 'Sandra', 'in', 'the', 'office', '?'], 'yes')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('./data_in/babi_train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "print( train_data[10] )\n",
    "train_data[0][0:3]\n",
    "\n",
    "\n",
    "#First we will build a set of all the words in the dataset:\n",
    "vocab = set()\n",
    "for story, question, answer in train_data:\n",
    "    vocab = vocab.union(set(story)) #Set returns unique words in the sentence\n",
    "                                    #Union returns the unique common elements from a two sets\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back\n",
      "bathroom\n",
      "bedroom\n"
     ]
    }
   ],
   "source": [
    "for x in vocab :\n",
    "    if( x.startswith('b')) :\n",
    "        print( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate len and add 1 for Keras placeholder - Placeholders are used to feed in the data to the network. \n",
    "#They need a data type, and have optional shape arguements.\n",
    "#They will be empty at first, and then the data will get fed into the placeholder\n",
    "\n",
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve test data\n",
    "\n",
    "with open('./data_in/babi_test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "    \n",
    "#Now we are going to calculate the longest story and the longest question\n",
    "#We need this for the Keras pad sequences. \n",
    "\n",
    "#Keras training layers expect all of the input to have the same length, so \n",
    "#we need to pad \n",
    "\n",
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = (max(all_story_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이제 Babi 데이터의 문장을 벡터로 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will go through a manual process of how to vectorize the data, and then we will create a function that does this automatically for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print( keras.__version__ )\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the tokenizer object:\n",
    "\n",
    "tokenizer = Tokenizer(filters = [])\n",
    "\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'apple': 2,\n",
       " 'put': 3,\n",
       " 'the': 4,\n",
       " 'office': 5,\n",
       " 'bathroom': 6,\n",
       " 'picked': 7,\n",
       " 'kitchen': 8,\n",
       " 'football': 9,\n",
       " 'garden': 10,\n",
       " 'travelled': 11,\n",
       " 'went': 12,\n",
       " 'grabbed': 13,\n",
       " 'john': 14,\n",
       " 'discarded': 15,\n",
       " 'there': 16,\n",
       " 'down': 17,\n",
       " 'in': 18,\n",
       " 'up': 19,\n",
       " '.': 20,\n",
       " 'mary': 21,\n",
       " 'hallway': 22,\n",
       " 'journeyed': 23,\n",
       " 'dropped': 24,\n",
       " 'to': 25,\n",
       " 'daniel': 26,\n",
       " 'got': 27,\n",
       " 'is': 28,\n",
       " 'yes': 29,\n",
       " 'moved': 30,\n",
       " 'no': 31,\n",
       " 'bedroom': 32,\n",
       " '?': 33,\n",
       " 'milk': 34,\n",
       " 'back': 35,\n",
       " 'sandra': 36,\n",
       " 'left': 37}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary that maps every word in our vocab to an index\n",
    "# It has been automatically lowercased\n",
    "#This tokenizer can give different indexes for different words depending on when we run it\n",
    "\n",
    "\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the stories, questions and answers:\n",
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating each of the elements\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question) \n",
    "    train_answers.append(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the text into the indexes \n",
    "\n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for vectorizing the stories, questions and answers:\n",
    "\n",
    "def vectorize_stories(data,word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\n",
    "    #vectorized stories:\n",
    "    X = []\n",
    "    #vectorized questions:\n",
    "    Xq = []\n",
    "    #vectorized answers:\n",
    "    Y = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        #Getting indexes for each word in the story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        #Getting indexes for each word in the story\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        #For the answers\n",
    "        y = np.zeros(len(word_index) + 1) #Index 0 Reserved when padding the sequences\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    #Now we have to pad these sequences:\n",
    "    return(pad_sequences(X,maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, 21, 30, 25,  4,  6, 20, 36, 23, 25,  4, 32, 20, 21, 12, 35,\n",
       "       25,  4, 32, 20, 26, 12, 35, 25,  4, 22, 20, 36, 12, 25,  4,  8, 20,\n",
       "       26, 12, 35, 25,  4,  6, 20, 26,  7, 19,  4,  9, 16, 20, 26, 12, 25,\n",
       "        4, 32, 20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_story_text[3]\n",
    "\n",
    "train_story_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 6, 24, 27, 29, 19, 8, 30, 24, 27, 37, 19]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_story_seq[3]\n",
    "\n",
    "train_story_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교재 36페이지의 input-output mapping 참고\n",
    "\n",
    "\n",
    "# 벡터 대응시키는 모델 (뉴럴네트워크)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create the placeholders \n",
    "#The Input function is used to create a keras tensor\n",
    "#PLACEHOLDER shape = (max_story_len,batch_size)\n",
    "#These are our placeholder for the inputs, ready to recieve batches of the stories and the questions\n",
    "\n",
    "input_sequence = Input((max_story_len,)) #As we dont know batch size yet\n",
    "\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 156), dtype=float32)\n",
      "Tensor(\"input_2:0\", shape=(None, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print( input_sequence )\n",
    "\n",
    "print( question )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encocder + decoder \n",
    "\n",
    "## 교재 129 페이지 참고\n",
    "\n",
    "![title](images/babiMNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left part of the previous image we can see a representation of a single layer of this model. Two different embeddings are calculated for each sentence, A and C. Also, the query or question q is embedded, using the B embedding.\n",
    "\n",
    "The A embeddings mi, are then computed using an inner product with the question embedding u (this is the part where the attention is taking place, as by computing the inner product between these embeddings what we are doing is looking for matches of words from the query and the sentence, to then give more importance to these matches using a Softmax function on the resulting terms of the dot product).\n",
    "\n",
    "Lastly, we compute the output vector o using the embeddings from C (ci), and the weights or probabilities pi obtained from the dot product. With this output vector o, the weight matrix W, and the embedding of the question u, we can finally calculate the predicted answer a hat.\n",
    "\n",
    "To build the entire network, we just repeat these procedure on the different layers, using the predicted output from one of them as the input for the next one. This is shown on the right part of the previous image.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "They have to have the same dimension as the data that will be fed, and can also have a batch size defined, although we can leave it blank if we dont know it at the time of creating the placeholders.\n",
    "\n",
    "Now we have to create the embeddings mentioned in the paper, A, C and B. An embedding turns an integer number (in this case the index of a word) into a d dimensional vector, where context is taken into account. Word embeddings are widely used in NLP and is one of the techniques that has made the field progress so much in the recent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder A:\n",
    "\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (Samples, story_maxlen,embedding_dim) -- Gives a list of the lenght of the samples where each item has the\n",
    "#lenght of the max story lenght and every word is embedded in the embbeding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder C:\n",
    "\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_len)) #From paper\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create question encoder:\n",
    "#Create input encoder B:\n",
    "\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_len)) #From paper\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, question_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets encode the sequences, passing the placeholders into our encoders:\n",
    "\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ++++++++++++++++++++++++\n",
    "\n",
    "Once we have created the two embeddings for the input sentences, and the embeddings for the questions, we can start defining the operations that take place in our model. As mentioned previously, we compute the attention by doing the dot product between the embedding of the questions and one of the embeddings of the stories, and then doing a softmax. The following block shows how this is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use dot product to compute similarity between input encoded m and question \n",
    "#Like in the paper:\n",
    "\n",
    "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we need to calculate the output o adding the match matrix with the second input vector sequence, and then calculate the response using this output and the encoded question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the response we want to add this match with the ouput of input_encoded_c\n",
    "\n",
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have the response we can concatenate it with the question encoded:\n",
    "\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, once this is done we add the rest of the layers of the model, adding an LSTM layer (instead of an RNN like in the paper), a dropout layer and a final softmax to compute the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the answer tensor with a RNN (LSTM)\n",
    "\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization with dropout:\n",
    "\n",
    "answer = Dropout(0.5)(answer)\n",
    "\n",
    "#Output layer:\n",
    "\n",
    "answer = Dense(vocab_len)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to output a probability distribution for the vocab, using softmax:\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 Model !!\n",
    "\n",
    "Notice here that the output is a vector of the size of the vocabulary (that is, the length of the number of words known by the model), where all the positions should be zero except the ones at the indexes of ‘yes’ and ‘no’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the final model:\n",
    "\n",
    "model = Model([input_sequence,question], answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Categorical instead of binary cross entropy as because of the way we are training\n",
    "#we could actually see any of the words from the vocab as output\n",
    "#however, we should only see yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 38)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 38)           1482        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 38)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 38)           0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 38)           0           activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 40,212\n",
      "Trainable params: 40,212\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two lines we build the final model, and compile it, that is, define all the maths that will be going on in the background by specifying an optimiser, a loss function and a metric to optimise.\n",
    "\n",
    "Now its time to train the model, here we need to define the inputs to the training, (the input stories, questions and answers), the batch size that we will be feeding the model with (that is, how many inputs at once), and the number of epochs that we will train the model for (that is, how many times the model will go through the training data in order to update the weights). I used 1000 epochs and obtained an accuracy of 98%, but even with 100 to 200 epochs you should get some pretty good results.\n",
    "\n",
    "Note that depending on your hardware, this training might take a while. Just relax, sit back, keep reading Medium and wait until its done.\n",
    "\n",
    "After its completed the training you might be left wondering “am I going to have to wait this long every time I want to use the model?” the obvious answer my friend is, NO. Keras allows developers to save a certain model it has trained, with the weights and all the configurations. The following block of code shows how this is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( answers_train.shape )\n",
    "answers_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 104us/step\n",
      "[3.637576064300537, 0.0]\n"
     ]
    }
   ],
   "source": [
    "val=model.evaluate( [inputs_train, questions_train], answers_train, \n",
    "                    batch_size = 32)\n",
    "print(val)\n",
    "\n",
    "# 길이가 38인 곳으로 랜덤하게 가기에, 확률적으로 1/38\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026316524\n"
     ]
    }
   ],
   "source": [
    "my_story = 'Sandra picked up the milk . Mary travelled left . '\n",
    "my_question = 'Sandra got the milk ?'\n",
    "\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)\n",
    "\n",
    "pred_results = model.predict(([my_story,my_ques]))\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "print(pred_results[0][val_max])\n",
    "      \n",
    "# 맟출 확률이 1/38\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "\n",
    "\n",
    "\n",
    "# 여기의 숫자 ? 확률적으로 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 깡통인 모델에 이미 학습한 것을 주입하자\n",
    "\n",
    "\n",
    "\n",
    "모델 학습과정 설정하기\n",
    "\n",
    "        학습하기 전에 학습에 대한 설정을 수행합니다.\n",
    "        손실 함수 및 최적화 방법을 정의합니다.\n",
    "        케라스에서는 compile() 함수를 사용합니다.\n",
    "    \n",
    "모델 학습시키기\n",
    "\n",
    "        훈련셋을 이용하여 구성한 모델로 학습시킵니다.\n",
    "        케라스에서는 fit() 함수를 사용합니다.\n",
    "    \n",
    "학습과정 살펴보기\n",
    "\n",
    "        모델 학습 시 훈련셋, 검증셋의 손실 및 정확도를 측정합니다.\n",
    "        반복횟수에 따른 손실 및 정확도 추이를 보면서 학습 상황을 판단합니다.\n",
    "    \n",
    "모델 평가하기\n",
    "\n",
    "        준비된 시험셋으로 학습한 모델을 평가합니다.\n",
    "        케라스에서는 evaluate() 함수를 사용합니다.\n",
    "    \n",
    "모델 사용하기\n",
    "\n",
    "        임의의 입력으로 모델의 출력을 얻습니다.\n",
    "        케라스에서는 predict() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공부한 AI 두뇌 model 을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "##################################################\n",
    "#To load a model that we have already trained and saved:\n",
    "# batch_size=32 , epochs=350 이상 훈련시킨 모델 부름 \n",
    "\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "model = load_model('./data_out/babi_chatbot_50.h5')\n",
    "\n",
    "###################################################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "\n",
    "\n",
    "# 더 공부를 시키자 !!\n",
    "\n",
    "# 공부한 것을 저장시키자 !!\n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training and testing the model\n",
    "\n",
    "## Saving the model +++++++++++\n",
    "\n",
    "## 학습 평가를 Matplotlib 그래프로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 2.4825 - accuracy: 0.4756 - val_loss: 0.6502 - val_accuracy: 0.6070\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.6337 - accuracy: 0.6368 - val_loss: 0.5686 - val_accuracy: 0.6950\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.5334 - accuracy: 0.7335 - val_loss: 0.4622 - val_accuracy: 0.7970\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.4368 - accuracy: 0.8091 - val_loss: 0.4093 - val_accuracy: 0.8230\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.4026 - accuracy: 0.8313 - val_loss: 0.4117 - val_accuracy: 0.8350\n",
      "10000/10000 [==============================] - 1s 90us/step\n",
      "[0.34663112587928774, 0.8614000082015991]\n",
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping( monitor='val_loss', patience=100)\n",
    "\n",
    "history = model.fit([inputs_train,questions_train],answers_train, \n",
    "                    batch_size = 32, epochs = 150, \n",
    "                    validation_data = ([inputs_test,questions_test],answers_test),\n",
    "                    callbacks=[early_stopping_callback]  )\n",
    "\"\"\"\n",
    "# 위의 코드는 학습데이터 정확도는 up, 테스트 데이터 정확도가 정체된 오버휫팅때 스탑시킴\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit([inputs_train,questions_train],answers_train, \n",
    "                    batch_size = 32, epochs = 5, \n",
    "                    validation_data = ([inputs_test,questions_test],answers_test) )\n",
    "\n",
    "val=model.evaluate( [inputs_train,questions_train], answers_train, \n",
    "                    batch_size = 32)\n",
    "\n",
    "\n",
    "print(val)\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "\n",
    "filename = './data_out/babi_chatbot.h5'\n",
    "\n",
    "model.save(filename)\n",
    "\n",
    "\n",
    "# 길이가 38인 곳으로 랜덤하게 가기에, 확률적으로 1/38\n",
    "\n",
    "\n",
    "########################################\n",
    "\n",
    "# model.fit 안하면 history 없어서 ==> 에러 \n",
    "# NameError: name 'history' is not defined\n",
    "\n",
    "\n",
    "#Lets plot the increase of accuracy as we increase the number of training epochs\n",
    "#We can see that without any training the acc is about 50%, random guessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch_size = 32 와 epochs=50 의 시작\n",
    "\n",
    "Train on 10000 samples, validate on 1000 samples\n",
    "\n",
    "Epoch 1/50\n",
    "    10000/10000 [==============================] - 7s 686us/step - loss: 0.8794 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
    "\n",
    "Epoch 2/50\n",
    "    10000/10000 [==============================] - 6s 570us/step - loss: 0.7019 - accuracy: 0.4998 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
    "\n",
    "\n",
    "\n",
    "# batch_size = 64 와 epochs=50 의 끝\n",
    "\n",
    "Epoch 48/50\n",
    "    10000/10000 [==============================] - 5s 530us/step - loss: 0.3619 - accuracy: 0.8410 - val_loss: 0.4453 - val_accuracy: 0.7980\n",
    "\n",
    "Epoch 49/50\n",
    "    10000/10000 [==============================] - 5s 542us/step - loss: 0.3586 - accuracy: 0.8406 - val_loss: 0.4490 - val_accuracy: 0.7950\n",
    "\n",
    "Epoch 50/50\n",
    "    10000/10000 [==============================] - 5s 547us/step - loss: 0.3553 - accuracy: 0.8424 - val_loss: 0.4508 - val_accuracy: 0.8030\n",
    "\n",
    "\n",
    "\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "\n",
    "# batch_size = 32 에 epochs=50 결과\n",
    "\n",
    "\n",
    "![title](images/babi_train_start.png)\n",
    "\n",
    "# batch_size = 32 에 epochs=100 결과\n",
    "\n",
    "![title](images/babi_train.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [문제] 학습데이터의 정확도는 높아지는데, 테스트 데이터는 정지됨 !!\n",
    "\n",
    "### 과적합 over-fitting의 개념을 이해하고, 테스트 데이터 정확도를 높이는 방법을 탐구 !\n",
    "\n",
    "<p>\n",
    "    \n",
    "### 1. 일만개의 학습데이터와 천개의 테스크 데이터로 나뉘어 있다. 데이터를 일만천개로 바꾸어, \n",
    "### 돌아가며 k-fold cross validation 하는 방법을 알아보라 (데이터의 양이 적은 경우에 필요)\n",
    "    \n",
    "<p>\n",
    "    \n",
    "### 2. Keras 모델의 한계일 수 있다. Hidden layer 갯수나 딥러닝 알고리즘을 바꾸어 학습을 시킨다, \n",
    "### 인터넷 등에서 새로운 여러가지 딥러닝 알고리즘을 알아보고, 이를 Babi 에 적용한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 현재의 딥러닝 모델 \n",
    "<pre>\n",
    "Model: \"model_1\"\n",
    "__________________________________________________________________________________________________\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "input_1 (InputLayer)            (None, 156)          0                                            \n",
    "__________________________________________________________________________________________________\n",
    "input_2 (InputLayer)            (None, 6)            0                                            \n",
    "__________________________________________________________________________________________________\n",
    "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
    "                                                                 sequential_3[1][0]               \n",
    "__________________________________________________________________________________________________\n",
    "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
    "__________________________________________________________________________________________________\n",
    "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
    "                                                                 sequential_2[1][0]               \n",
    "__________________________________________________________________________________________________\n",
    "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
    "__________________________________________________________________________________________________\n",
    "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
    "                                                                 sequential_3[1][0]               \n",
    "__________________________________________________________________________________________________\n",
    "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
    "__________________________________________________________________________________________________\n",
    "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
    "==================================================================================================\n",
    "Total params: 38,730\n",
    "Trainable params: 38,730\n",
    "Non-trainable params: 0\n",
    "__________________________________________________________________________________________________\n",
    "</pre>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==========================================\n",
    "\n",
    "# 학습된 AI 두뇌 모델 evaluate   !!!! \n",
    "\n",
    "\n",
    "# ==================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 94us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34663112587928774, 0.8614000082015991]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# print( answers_train.shape  ) ==> ( 10000, 38 ) one hot vector\n",
    "\n",
    "### train 에 대해서 evaluate 한다 //////// test 데이터로 하는 것과 차이 ?? ///////\n",
    "\n",
    "val=model.evaluate( [inputs_train,questions_train], answers_train, batch_size = 32)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "val  \n",
    "\n",
    "# 50 때 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==========================================\n",
    "\n",
    "# 학습된 AI 두뇌 테스트를 위해 문제를 출제 !!!! \n",
    "\n",
    "\n",
    "# ===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3464513e-09 4.7893756e-09 5.9277316e-09 ... 5.8098868e-09\n",
      "  6.7517063e-09 5.7777618e-09]\n",
      " [1.1304347e-08 9.6045669e-09 1.1915859e-08 ... 1.1772948e-08\n",
      "  1.3240343e-08 1.3179218e-08]\n",
      " [4.7399933e-08 3.1272307e-08 4.0516948e-08 ... 4.2989544e-08\n",
      "  4.5466496e-08 4.3368548e-08]\n",
      " ...\n",
      " [2.2156049e-08 1.7657909e-08 2.2862498e-08 ... 2.3986395e-08\n",
      "  2.4334682e-08 2.7791978e-08]\n",
      " [5.1913876e-08 3.6524860e-08 4.4735319e-08 ... 4.9788913e-08\n",
      "  5.2742969e-08 4.8548156e-08]\n",
      " [5.2890915e-08 3.6501500e-08 5.2736290e-08 ... 5.5532698e-08\n",
      "  5.7155237e-08 6.0597074e-08]]\n"
     ]
    }
   ],
   "source": [
    "#Lets check out the predictions on the test set:\n",
    "#These are just probabilities for every single word on the vocab\n",
    "# 테스트 데이터 기반의 prediction ##############################\n",
    "\n",
    "\n",
    "pred_results = model.predict(([inputs_test,questions_test]))\n",
    "\n",
    "print( pred_results )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are an array, as mentioned earlier that contain in every position the probabilities of each of the words in the vocabulary being the answer to the question. If we look at the first element of this array, we will see a vector of the size of the vocabulary, where all the times are close to 0 except the ones corresponding to yes or no.\n",
    "\n",
    "Out of these, if we pick the index of the highest value of the array and then see to which word it corresponds to, we should find out if the answer is affirmative or negative.\n",
    "\n",
    "One fun thing that we can do now, is create our own stories and questions, and feed them to the bot to see what he says!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167208\n"
     ]
    }
   ],
   "source": [
    "my_story = 'Sandra picked up the milk . Mary travelled left . '\n",
    "my_question = 'Sandra got the milk ?'\n",
    "\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)\n",
    "\n",
    "pred_results = model.predict(([my_story,my_ques]))\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "print(pred_results[0][val_max])\n",
    "      \n",
    "# 맟출 확률이 1/38\n",
    "# 50 에서는 0.579\n",
    "# 100 dptj 0.69\n",
    "# 150 에서 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1539566e-09, 2.0857203e-09, 2.1775060e-09, 1.6845408e-09,\n",
       "       8.3016913e-14, 2.4515723e-09, 1.7732332e-09, 1.8030241e-09,\n",
       "       2.0983812e-09, 2.5064566e-09, 1.7346922e-09, 2.6375377e-09,\n",
       "       2.6769633e-09, 1.9282695e-09, 2.0566882e-09, 2.1949988e-09,\n",
       "       2.7570446e-09, 2.2814801e-09, 2.1163804e-09, 1.9202608e-09,\n",
       "       1.7847666e-09, 3.2790710e-09, 1.9234943e-09, 1.9196751e-09,\n",
       "       1.8828541e-09, 1.9834059e-09, 1.6332830e-09, 2.6791394e-09,\n",
       "       3.1429914e-09, 8.3279103e-02, 2.2346143e-09, 9.1672081e-01,\n",
       "       1.8621893e-09, 1.9928785e-09, 9.0607491e-13, 2.0374977e-09,\n",
       "       2.4011575e-09, 2.4124640e-09], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the probabilities for the vocab words using the 1st sentence\n",
    "\n",
    "\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9167208"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See probability:\n",
    "\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, we can make our own questions using the vocabulary we have\n",
    "\n",
    "print( len(vocab)   )\n",
    "vocab\n",
    "\n",
    "# 'office': 1\n",
    "# '?': 37  == 마지막 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Sandra picked up the milk . Mary travelled left . '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'the',\n",
       " 'milk',\n",
       " '.',\n",
       " 'Mary',\n",
       " 'travelled',\n",
       " 'left',\n",
       " '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    my_story = 'Sandra picked up the milk . Mary travelled left . '\n",
    "    my_question = 'Sandra got the milk ?'\n",
    "    my_data = [(my_story.split(), my_question.split(),'yes')]\n",
    "    my_story, my_ques, my_ans = vectorize_stories(my_data)\n",
    "    pred_results = model.predict(([my_story,my_ques]))\n",
    "    val_max = np.argmax(pred_results[0])\n",
    "    print(pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = 'Sandra got the milk ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra', 'got', 'the', 'milk', '?']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the data in the same format as before\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize this data\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38)\n",
      "yes :  1.633283e-09\n",
      "no :  2.412464e-09\n",
      "0.6770186\n"
     ]
    }
   ],
   "source": [
    "#Make the prediction\n",
    "\n",
    "pred_results = model.predict(([my_story,my_ques]))\n",
    "\n",
    "print( pred_results.shape  )\n",
    "print( 'yes : ', pred_results[0][26] )\n",
    "print( 'no : ', pred_results[0][37] )\n",
    "print( pred_results[0][26]/ pred_results[0][37] )\n",
    "\n",
    "# 50 일때 yes / no = 0.986 거의 같은 확률 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     'yes': 24,\n",
    " 'left': 25,\n",
    " 'to': 26,\n",
    " 'milk': 27,\n",
    " 'in': 28,\n",
    " 'moved': 29,\n",
    " 'discarded': 30,\n",
    " \n",
    "     'no': 31,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "print( val_max )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "#Correct prediction!\n",
    "\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "        \n",
    "print(val)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9167208"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confidence\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649988\n",
      "10000/10000 [==============================] - 1s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34663112587928774, 0.8614000082015991]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story = 'Sandra picked up the milk . Sandra moved to the bathroom . '\n",
    "my_question = 'Is the milk in the bathroom ?'\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)\n",
    "pred_results = model.predict(([my_story,my_ques]))\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "print(pred_results[0][val_max])\n",
    "###############################\n",
    "# 50 에서는 0.9748\n",
    "# 100 에서는 0.974858\n",
    "# 150 에서 0.6165\n",
    "\n",
    "model.evaluate([inputs_train,questions_train],answers_train, \n",
    "                    batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "37\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "print( val_max )\n",
    "\n",
    "#Correct prediction!\n",
    "\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "        \n",
    "print(val)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================================\n",
    "\n",
    "<p> &nbsp;\n",
    "\n",
    "    \n",
    "한 장에 모아쓴 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Permute, dot, add, concatenate\n",
    "from keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split('(\\W+)+', sent) if x.strip()]\n",
    "\n",
    "def parse_stories(lines):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            # Provide all the substories\n",
    "            substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f):\n",
    "    data = parse_stories(f.readlines())\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data]\n",
    "    return data\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        y = np.zeros(len(word_idx) + 1)\n",
    "        y[word_idx[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X, maxlen=story_maxlen),\n",
    "            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))\n",
    "\n",
    "\n",
    "class TrainingVisualizer(keras.callbacks.History):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        pd.DataFrame({key: value for key, value in self.history.items() if key.endswith('loss')}).plot()\n",
    "        axes = pd.DataFrame({key: value for key, value in self.history.items() if key.endswith('acc')}).plot()\n",
    "        axes.set_ylim([0, 1])\n",
    "        plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "tar = tarfile.open(path)\n",
    "\n",
    "\n",
    "challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "\n",
    "print('Extracting stories for the challenge: single_supporting_fact_10k')\n",
    "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "print( len(train_stories), len(test_stories) )\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print( train_stories[0] )\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
    "                                                               word_idx,\n",
    "                                                               story_maxlen,\n",
    "                                                               query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
    "                                                            word_idx,\n",
    "                                                            story_maxlen,\n",
    "                                                            \n",
    "                                                            \n",
    "print('-------------------------')\n",
    "print('Vocabulary:\\n',vocab,\"\\n\")\n",
    "print('Vocab size:', vocab_size, 'unique words')\n",
    "print('Story max length:', story_maxlen, 'words')\n",
    "print('Query max length:', query_maxlen, 'words')\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print('-------------------------')\n",
    "                                                            \n",
    "print('-------------------------')\n",
    "print('inputs: integer tensor of shape (samples, max_length)')\n",
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)\n",
    "print('input train sample', inputs_train[0,:])\n",
    "print('-------------------------')\n",
    "                                                            \n",
    "print('-------------------------') \n",
    "print('queries: integer tensor of shape (samples, max_length)') \n",
    "print('queries_train shape:', queries_train.shape) \n",
    "print('queries_test shape:', queries_test.shape) \n",
    "print('query train sample', queries_train[0,:]) \n",
    "\n",
    "                                                            \n",
    "print('-------------------------') \n",
    "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)') \n",
    "print('answers_train shape:', answers_train.shape) \n",
    "print('answers_test shape:', answers_test.shape) \n",
    "print('answer train sample', answers_train[0,:]) \n",
    "print('-------------------------')\n",
    "                                                            \n",
    "                                                            \n",
    "                                                            \n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 100\n",
    "batch_size = 32\n",
    "lstm_size = 64\n",
    "embed_size = 50\n",
    "dropout_rate = 0.3\n",
    "\n",
    "\n",
    "# placeholders\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "print('Input sequence:', input_sequence)\n",
    "print('Question:', question)\n",
    "\n",
    "# encoders\n",
    "# embed the input sequence into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=query_maxlen))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=query_maxlen))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "print('Input encoded m', input_encoded_m)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "question_encoded = question_encoder(question)\n",
    "print('Question encoded', question_encoded)\n",
    "\n",
    "\n",
    "# compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, query_maxlen)\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "print(match.shape)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match.shape)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "print('Response shape', response)\n",
    "\n",
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs, callbacks=[TrainingVisualizer()],\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "        current_inp = test_stories[i]\n",
    "        current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
    "        current_prediction = model.predict([current_story, current_query])\n",
    "        current_prediction = idx_word[np.argmax(current_prediction)]\n",
    "        print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
    "        print(\"-----------------------------------------------------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('-------------------------------------------------------------------------------------------')\n",
    "# print('Custom User Queries (Make sure there are spaces before each word)')\n",
    "# while 1:\n",
    "#     print('-------------------------------------------------------------------------------------------')\n",
    "#     print('Please input a story')\n",
    "#     user_story_inp = input().split(' ')\n",
    "#     print('Please input a query')\n",
    "#     user_query_inp = input().split(' ')\n",
    "#     user_story, user_query, user_ans = vectorize_stories([[user_story_inp, user_query_inp, '.']], word_idx, story_maxlen, query_maxlen)\n",
    "#     user_prediction = model.predict([user_story, user_query])\n",
    "#     user_prediction = idx_word[np.argmax(user_prediction)]\n",
    "#     print('Result')\n",
    "#     print(' '.join(user_story_inp), ' '.join(user_query_inp), '| Prediction:', user_prediction)\n",
    "\n",
    "# Mary went to the bathroom . John moved to the hallway . Mary travelled to the office . # Where is Mary ?\n",
    "# Sandra travelled to the office . John journeyed to the garden ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================================\n",
    "\n",
    "<p> &nbsp;\n",
    "\n",
    "# [생각] 영어 데이터를 한글 번역기로 번역을 시킨다.\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# [생각] 한글용 Babi 데이터로 한글 QA 만들어본다.\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# [생각] 수학학습 질문과 답변 데이터로 만들어본다.\n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# web 버젼, attention 버젼\n",
    "\n",
    "\n",
    "# https://github.com/vinhkhuc/MemN2N-babi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ++++++++++++++++++++++++++++++++++\n",
    "\n",
    "<p> &nbsp;\n",
    "\n",
    "# sequence 2 sequence  실험 \n",
    "\n",
    "<p> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "char_arr = [c for c in \"SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑봉구우루\"]\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "seq_data = [['word', \"단어\"], [\"wood\", \"나무\"], [\"game\", \"놀이\"], [\"girl\", \"소녀\"], \n",
    "            [\"kiss\", \"키스\"], [\"love\", \"사랑\"], [\"bong\", \"봉구\"], [\"uruu\", \"우루\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    target_batch = []\n",
    "    \n",
    "    for seq in seq_data:\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in (\"S\" + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + \"E\")]\n",
    "        \n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        output_batch.append(np.eye(dic_len)[output])\n",
    "        target_batch.append(target)\n",
    "        \n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-8ef07e5ed546>:16: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-8ef07e5ed546>:19: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "n_hidden = 128\n",
    "total_epoch = 1000\n",
    "\n",
    "n_class = n_input = dic_len\n",
    "\n",
    "enc_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "dec_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "targets = tf.placeholder(tf.int64, [None, None])\n",
    "\n",
    "\n",
    "# encoder: [batch size, time steps, input size]\n",
    "# decoder: [batch size, time steps]\n",
    "\n",
    "with tf.variable_scope(\"encode\"):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    \n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input, dtype=tf.float32)\n",
    "    \n",
    "with tf.variable_scope(\"decode\"):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    \n",
    "    outputs, dec_stats = tf.nn.dynamic_rnn(dec_cell, dec_input, \n",
    "                                           initial_state=enc_states, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-e5334240e8e5>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=model, labels=targets\n",
    "    )\n",
    ")\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0200, cost: 0.07781609892845154\n",
      "Epoch: 0400, cost: 0.025294050574302673\n",
      "Epoch: 0600, cost: 0.008742648176848888\n",
      "Epoch: 0800, cost: 0.004197845701128244\n",
      "Epoch: 1000, cost: 0.008464171551167965\n",
      "\n",
      "optimization complete\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "cost_val = []\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([opt, cost], feed_dict={enc_input: input_batch,\n",
    "                                               dec_input: output_batch,\n",
    "                                               targets: target_batch})\n",
    "    cost_val.append(loss)\n",
    "    \n",
    "    if (epoch+1) % 200 ==0:\n",
    "        print(\"Epoch: {:04d}, cost: {}\".format(epoch+1, loss))\n",
    "    \n",
    "    \n",
    "print(\"\\noptimization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"cost\")\n",
    "plt.plot(cost_val, linewidth=1, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==== translate test ====\n",
      "word -> 단어\n",
      "wodr -> 단무\n",
      "love -> 사랑\n",
      "loev -> 사랑\n",
      "bogn -> 봉구\n",
      "uruu -> 우루\n",
      "abcd -> 놀봉구\n"
     ]
    }
   ],
   "source": [
    "def translate(word):\n",
    "    seq_data = [word, \"P\" * len(word)]\n",
    "    \n",
    "    input_batch, output_batch, target_batch = make_batch([seq_data])\n",
    "    prediction = tf.argmax(model, 2)\n",
    "    \n",
    "    result = sess.run(prediction, feed_dict={enc_input: input_batch,\n",
    "                                             dec_input: output_batch,\n",
    "                                             targets: target_batch})\n",
    "    decoded = [char_arr[i] for i in result[0]]\n",
    "    \n",
    "    try:\n",
    "        end = decoded.index(\"E\")\n",
    "        translated = \"\".join(decoded[:end])\n",
    "        return translated\n",
    "        \n",
    "    except Exception as ex:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"\\n ==== translate test ====\")\n",
    "\n",
    "print(\"word -> {}\".format(translate(\"word\")))\n",
    "print(\"wodr -> {}\".format(translate(\"wodr\")))\n",
    "print(\"love -> {}\".format(translate(\"love\")))\n",
    "print(\"loev -> {}\".format(translate(\"loev\")))\n",
    "print(\"bogn -> {}\".format(translate(\"bogn\")))\n",
    "print(\"uruu -> {}\".format(translate(\"uruu\")))\n",
    "print(\"abcd -> {}\".format(translate(\"abcd\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  자동 단어 완성 !! (3글자 ==> 4글자)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/word_auto.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "import numpy as np\n",
    "\n",
    "char_arr = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\",\n",
    "            \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\n",
    "            \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\",\n",
    "            \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "\n",
    "seq_data = [\"word\", \"wood\", \"deep\", \"dive\", \"cold\", \"cool\", \"load\", \"love\", \"kiss\", \"kind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    \n",
    "    for seq in seq_data:\n",
    "        input = [num_dic[n] for n in seq[:-1]]\n",
    "        target = num_dic[seq[-1]]\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        target_batch.append(target)\n",
    "        \n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_hidden = 128\n",
    "total_epoch = 10000\n",
    "\n",
    "n_step = 3\n",
    "n_input = n_class = dic_len\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input], name=\"input_X\")\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-7ed5499ca873>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-15-7ed5499ca873>:6: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "# MultiRNNCell 함수를 사용하여 조합\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y)   \n",
    ")\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000, cost= 4.428016836754978e-05\n",
      "Epoch: 4000, cost= 1.1086447102570673e-06\n",
      "Epoch: 6000, cost= 0.00020040673553012311\n",
      "Epoch: 8000, cost= 1.192092824453539e-08\n",
      "Epoch: 10000, cost= 3.576278473360617e-08\n",
      "\n",
      "optimization complete\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "input_batch, output_batch = make_batch(seq_data)\n",
    "\n",
    "cost_epoch = []\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([opt, cost], feed_dict={X: input_batch, Y: output_batch})\n",
    "    cost_epoch.append(loss)\n",
    "    \n",
    "    if (epoch+1) % 2000 ==0:\n",
    "        print(\"Epoch: {}, cost= {}\".format(epoch+1, loss))\n",
    "        \n",
    "print(\"\\noptimization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHcAAAF1CAYAAABiXwa3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de7TlZ1kf8O/z2+fMJZeZQDIkIRdCECGRotIsvFCtRS0gXrpKXYV6a2tXWpeotS5dUGsvrtVWe1HromWJSMVbUBFblijCoiJeMHFCEAkRDCEhQ0IySUgmk7mdy9s/9s4wkzln732Sc2b/9szns9as2ft39tnznJP9Zvb5zvM+b7XWAgAAAMB86mZdAAAAAABPnnAHAAAAYI4JdwAAAADmmHAHAAAAYI4JdwAAAADmmHAHAAAAYI4JdwAAAADmmHAHAGCMqnp/Vf2zWdcBALAe4Q4AAADAHBPuAABnnKq6oqreUVX7q+rBqnpDVXVV9W+q6q6qur+qfqmqdo8ev6OqfmX02Ier6s+r6uKq+o9JvirJG6rqYFW9YbZfGQDAqYQ7AMAZpaoGSX4nyV1JrkpyWZK3JfnHo19/J8nVSc5L8nhY811Jdie5IsmFSf5FksOttR9N8kdJXttaO6+19trT9XUAAExLuAMAnGlenOSZSX64tfZYa+1Ia+2Pk3xbkp9qrd3RWjuY5PVJXl1VC0mWMgx1vqC1ttJau7m1dmBmXwEAwAYIdwCAM80VSe5qrS0/4fozM+zmedxdSRaSXJzkl5P8fpK3VdU9VfVfqmrxtFQLAPAUCXcAgDPN3UmuHHXknOieJM864f6VSZaT3NdaW2qt/YfW2rVJvjLJNyb5ztHj2lYXDADwVAh3AIAzzU1J7k3yE1V17mhY8kuS3JDkB6vq2VV1XpL/lOTXW2vLVfV3qupvjOb1HMhwm9bK6Pnuy3BGDwBALwl3AIAzSmttJck3JfmCJJ9Osi/JP0zylgy3X30gyaeSHEnyfaNPuyTJ2zMMdm5L8odJfmX0sf+R5B9U1eeq6mdP05cBADC1ak2nMQAAAMC80rkDAAAAMMeEOwAAAABzTLgDAAAAMMeEOwAAAABzTLgDAAAAMMcWtuJJL7roonbVVVdtxVMDAAAAnJVuvvnmB1pre554fUvCnauuuip79+7diqcGAAAAOCtV1V1rXbctCwAAAGCOCXcAAAAA5phwBwAAAGCOCXcAAAAA5phwBwAAAGCOCXcAAAAA5phwBwAAAGCOCXcAAAAA5phwBwAAAGCOCXcAAAAA5phwBwAAAGCOCXfWsbracmRpZdZlAAAAAIwl3FnHrfccyKve+KezLgMAAABgLOHOOrouWW2zrgIAAABgPOHOOrqqrEp3AAAAgJ4T7qxj0FVWmnAHAAAA6Dfhzjp07gAAAADzQLizDp07AAAAwDwQ7qxjUJUVnTsAAABAzwl31tF1sS0LAAAA6D3hzjpsywIAAADmgXBnHcNtWbOuAgAAAGA84c46uq6yqnMHAAAA6DnhzjoMVAYAAADmgXBnHV1XBioDAAAAvSfcWYeBygAAAMA8EO6sw7YsAAAAYB4Id9bRdTFQGQAAAOg94c46dO4AAAAA80C4s46uKrIdAAAAoO+EO+voukoSJ2YBAAAAvSbcGcOJWQAAAEDfCXfGMHcHAAAA6DvhzhhOzAIAAAD6Trgzhs4dAAAAoO+EO2N0XWV1ddZVAAAAAKxPuDOGgcoAAABA3wl3xrAtCwAAAOg74c4YXVcGKgMAAAC9JtwZQ+cOAAAA0HfCnTEGnXAHAAAA6Lepw52qGlTVLVX1O1tZUJ90XWzLAgAAAHptI507P5Dktq0qpI9sywIAAAD6bqpwp6ouT/LKJG/e2nL6xUBlAAAAoO+m7dz5mSQ/kmR1vQdU1fVVtbeq9u7fv39Tipu1QVU07gAAAAB9NjHcqapvTHJ/a+3mcY9rrb2ptXZda+26PXv2bFqBs9TZlgUAAAD03DSdOy9J8s1VdWeStyV5aVX9ypZW1ROd07IAAACAnpsY7rTWXt9au7y1dlWSVyf5f621b9/yynpg4LQsAAAAoOc2clrWWcdpWQAAAEDfLWzkwa219yd5/5ZU0kNOywIAAAD6TufOGMPOnVlXAQAAALA+4c4YBioDAAAAfSfcGWNQtmUBAAAA/SbcGWOgcwcAAADoOeHOGF1XWdG5AwAAAPSYcGeMQSWrOncAAACAHhPujGFbFgAAANB3wp0xOgOVAQAAgJ4T7owx7NyZdRUAAAAA6xPujNF1OncAAACAfhPujGFbFgAAANB3wp0xBhUDlQEAAIBeE+6M0TktCwAAAOg54c4YA9uyAAAAgJ4T7ozhtCwAAACg74Q7Y3RdZUXnDgAAANBjwp0xBlVZNXMHAAAA6DHhzhgDA5UBAACAnhPujNEZqAwAAAD0nHBnjEEXnTsAAABArwl3xjBQGQAAAOg74c4YBioDAAAAfSfcGWM4UHnWVQAAAACsT7gzRle2ZQEAAAD9JtwZY9DZlgUAAAD0m3BnjK7iKHQAAACg14Q7YzgtCwAAAOg74c4YTssCAAAA+k64M4bTsgAAAIC+E+6M0VWZuQMAAAD0mnBnjGHnjnAHAAAA6C/hzhgGKgMAAAB9J9wZw0BlAAAAoO+EO2MMutiWBQAAAPSacGeMrmzLAgAAAPpNuDPGoLMtCwAAAOg34c4Yg66yItsBAAAAeky4M0ZnoDIAAADQc8KdMQZdGagMAAAA9JpwZwwDlQEAAIC+E+6MMegqTbgDAAAA9JhwZ4yuYlsWAAAA0GvCnTE6p2UBAAAAPSfcGWPgtCwAAACg54Q7YzgtCwAAAOg74c4YTssCAAAA+k64M8agsy0LAAAA6DfhzhiDLjp3AAAAgF4T7ozRGagMAAAA9JxwZ4xBZ+YOAAAA0G/CnTG6qqyszroKAAAAgPUJd8YYdJWmcwcAAADoMeHOGF1VVoU7AAAAQI8Jd8boKjFPGQAAAOgz4c4YpXMHAAAA6DnhzhhdJbIdAAAAoM+EO2OYuQMAAAD03cRwp6p2VNVNVfUXVXVrVf2H01FYHwh3AAAAgL5bmOIxR5O8tLV2sKoWk/xxVf1ea+3Ptri2matKVldnXQUAAADA+iaGO621luTg6O7i6NdZ0c7SdZWmcwcAAADosalm7lTVoKo+nOT+JO9trd24xmOur6q9VbV3//79m13nTDgKHQAAAOi7qcKd1tpKa+1Lklye5MVV9YI1HvOm1tp1rbXr9uzZs9l1zoSZOwAAAEDfbei0rNbaw0nen+TlW1JNz5TOHQAAAKDnpjkta09VXTC6vTPJ1yX5q60urA+6MnMHAAAA6LdpTsu6NMlbq2qQYRj0G62139nasvrBtiwAAACg76Y5LesjSb70NNTSOwYqAwAAAH23oZk7Z5vSuQMAAAD0nHBnjK4S2Q4AAADQZ8KdMczcAQAAAPpOuDOGcAcAAADoO+HOGGWgMgAAANBzwp0xuqo0nTsAAABAjwl3xnAUOgAAANB3wp0xzNwBAAAA+k64M0aNjkK3NQsAAADoK+HOGFV1POABAAAA6CPhzgS2ZgEAAAB9JtyZwFBlAAAAoM+EOxOUzh0AAACgx4Q7E3Rm7gAAAAA9JtyZwMwdAAAAoM+EOxMIdwAAAIA+E+5MUAYqAwAAAD0m3Jmgq0rTuQMAAAD0lHBnAkehAwAAAH0m3JnAzB0AAACgz4Q7E5RwBwAAAOgx4c4EXSWyHQAAAKCvhDsT2JYFAAAA9JlwZwIDlQEAAIA+E+5MUFVZle4AAAAAPSXcmaDrzNwBAAAA+ku4M4GZOwAAAECfCXcmEO4AAAAAfSbcmaAMVAYAAAB6TLgzQVeVpnMHAAAA6CnhzgSOQgcAAAD6TLgzgZk7AAAAQJ8JdyYo4Q4AAADQY8KdCbpKZDsAAABAXwl3JrAtCwAAAOgz4c4EBioDAAAAfSbcmcDMHQAAAKDPhDsTDGfuCHcAAACAfhLuTDCcuTPrKgAAAADWJtyZoKvKqnQHAAAA6CnhzgRloDIAAADQY8KdCboqM3cAAACA3hLuTNB1OncAAACA/hLuTNA5Ch0AAADoMeHOBCXcAQAAAHpMuDNBV4lsBwAAAOgr4c4EtmUBAAAAfSbcmaBzFDoAAADQY8KdCczcAQAAAPpMuDPBcOaOcAcAAADoJ+HOBMOZO7OuAgAAAGBtwp0JDFQGAAAA+ky4M0EZqAwAAAD0mHBngq7KzB0AAACgt4Q7E3SVrGjdAQAAAHpKuDOBgcoAAABAnwl3JigDlQEAAIAemxjuVNUVVfUHVXVbVd1aVT9wOgrri0EXM3cAAACA3lqY4jHLSX6otfahqjo/yc1V9d7W2se2uLZesC0LAAAA6LOJnTuttXtbax8a3X40yW1JLtvqwvrCtiwAAACgzzY0c6eqrkrypUlu3Ipi+qir6NwBAAAAemvqcKeqzkvyW0n+ZWvtwBofv76q9lbV3v37929mjTPVVZm5AwAAAPTWVOFOVS1mGOz8amvtHWs9prX2ptbada216/bs2bOZNc5UV8mq1h0AAACgp6Y5LauS/EKS21prP7X1JfVLGagMAAAA9Ng0nTsvSfIdSV5aVR8e/fqGLa6rNzoDlQEAAIAem3gUemvtj5PUaaill7pKZDsAAABAX23otKyzUdfp3AEAAAD6S7gzQTkKHQAAAOgx4c4EZu4AAAAAfSbcmWA4c0e4AwAAAPSTcGeCzlHoAAAAQI8JdyYo27IAAACAHhPuTNAZqAwAAAD0mHBngq7KzB0AAACgt4Q7Eww7d4Q7AAAAQD8JdyaoqqyszroKAAAAgLUJdyZY6Corq9IdAAAAoJ+EOxPc8/Dh/PwffWrWZQAAAACsSbgzwQ033T3rEgAAAADWJdyZpGZdAAAAAMD6hDsTyHYAAACAPhPuTPBfv/WLZ10CAAAAwLqEOxNcfdG5uebSXbMuAwAAAGBNwp0JFgddllcchQ4AAAD0k3BngoVBZWW1zboMAAAAgDUJdyZY6CpLqzp3AAAAgH4S7kywMOiysqJzBwAAAOgn4c4Ew84d4Q4AAADQT8KdCRY6M3cAAACA/hLuTLDQdVlyWhYAAADQU8KdCRYGlWUzdwAAAICeEu5M4Ch0AAAAoM+EOxMsdJ2j0AEAAIDeEu5MMOgqrSUHjizNuhQAAACAUwh3pnTrZw7MugQAAACAUwh3pnTBOYuzLgEAAADgFMKdKbzgsl1OzAIAAAB6SbgzhcVBl2MrhioDAAAA/SPcmcJCV1kW7gAAAAA9JNyZQlVl1a4sAAAAoIeEO1MYVKU16Q4AAADQP8KdKXRddO4AAAAAvSTcmUJXlVWdOwAAAEAPCXemUMIdAAAAoKeEO1PoKpHtAAAAAH0k3JmCbVkAAABAXwl3ptCVgcoAAABAPwl3pmDmDgAAANBXwp0pDGfuCHcAAACA/hHuTKGrysrqrKsAAAAAOJVwZwpdZ1sWAAAA0E/CnSk4LQsAAADoK+HOFIYzd2ZdBQAAAMCphDtT0LkDAAAA9JVwZwpVyapsBwAAAOgh4c4UdO4AAAAAfSXcmcJw5o5wBwAAAOgf4c4Uhp07s64CAAAA4FTCnSmUbVkAAABATwl3ptBVsqp1BwAAAOgh4c4UBp1tWQAAAEA/CXem4LQsAAAAoK+EO1N4z62fza/e+OlZlwEAAABwionhTlW9parur6qPno6C+uiVL7w01166a9ZlAAAAAJxims6dX0zy8i2uo9eedeG5OXf7wqzLAAAAADjFxHCntfaBJA+dhlp6a/tCl6PLK7MuAwAAAOAUZu5MYfviIMeWV2ddBgAAAMApNi3cqarrq2pvVe3dv3//Zj1tL2wbdDkq3AEAAAB6aNPCndbam1pr17XWrtuzZ89mPW0vbF/sdO4AAAAAvWRb1hS2D7r84Sf2Z2lFwAMAAAD0yzRHod+Q5INJnldV+6rqu7e+rH5ZXBh+mx45vDTjSgAAAABONvF879baa05HIX026Gr4e9WMKwEAAAA4mW1ZU2ht+PvK4zcAAAAAekK4M4WjyytJktVV4Q4AAADQL8KdKbz4qqcn0bkDAAAA9I9wZwoLgy6XXbAzyyvCHQAAAKBfhDtT6rpkVecOAAAA0DPCnSktdF1WzNwBAAAAeka4M6WuItwBAAAAeke4M6VBVwYqAwAAAL0j3JlSV6VzBwAAAOgd4c6UFgbCHQAAAKB/hDtT+uhnDuQ9t9436zIAAAAATiLc2YC3/MmnZl0CAAAAwEmEOxtwbHl11iUAAAAAnES4swEvuGz3rEsAAAAAOMnCrAuYF9/zNc/Jedt9uwAAAIB+0bkzpa6S1pyWBQAAAPSLcGdKg6o4CR0AAADoG+HOlKoqK9IdAAAAoGcMkZnSymrLo0eWZl0GAAAAwEl07kzpDX9we976wbtmXQYAAADASYQ7AAAAAHNMuAMAAAAwx4Q7AAAAAHNMuLNBrTkxCwAAAOgP4c6UfvQbrkmSHF1enXElAAAAAJ8n3JnSwqCSJEeWVmZcCQAAAMDnCXem9IoXXJokOaZzBwAAAOgR4c6ULtm9I5ddsNO2LAAAAKBXhDsb8JmHD+d/vf+Tsy4DAAAA4Djhzga977b7Zl3C3FldbU4ZAwAAgC0i3NmgVSHFhr3m5/8s3/bmG2ddBgAAAJyRFmZdwLxZXhXubNSNn3ooVbOuAgAAAM5MOnc26JJdO2ZdwlzS8AQAAABbQ+fOBrzqRZfni565a9ZlAAAAABync2cDdu1cMHMHAAAA6BWdOxtw4PByWjs86zIAAAAAjtO5swG/9aF9+cU/vXPWZcwdw5QBAABg6+jc2YAfftnz8pf7Hpl1GXOnktjMBgAAAFtD584GXLJrR3ZuG8y6DAAAAIDjhDsbsG2hy2/f8pkcXV6ZdSlzpezLAgAAgC0j3NmA7QvDb9e9Dx+ZcSXzRbQDAAAAW0e4swGPH4PuOPSN0bgDAAAAW0e4swF3PngoSfLS//6HM64EAAAAYEi4swFf9dyLZl3CXDJzBwAAALaOcGcDvuiZu4/f/qn3fmKGlcwX0Q4AAABsHeHOk/Sz7/vrWZcAAAAAINxh69mVBQAAAFtHuLNBL7z881uzHjh4NK9/x0dmWM18KBuzAAAAYMsIdzboy6++8PjtP7n9gdxw0935j+/62Awr6j+dOwAAALB1hDsb9K++/guP3/7YPQeSJD//R5+aVTkAAADAWU64s0E7FgfHb//cB+44fvtdH7l3FuXMBY07AAAAsHWEO5vke3/tQ7MuobfKviwAOKO88y/uyZGllVmXAQCMCHeehB2Lvm0bIdoBgDPL999wSz7wif2zLgMAGJFSPAm3/NjfnXUJc+ON7/9kHj26POsyAIBNttramtevet27ctDf/QBwWgl3noSd2wb53e//qlOueyNzqp9891/NugQAYAusrA5/X2t71oHDS6e5GgA4uwl3nqRrn7nrlGvf9ZabTrr/gU/sT1vnX7WmdfjYSpYef/cEANATK63ljv0H8/wfe/epH1t9au9/AICNEe48Bf/8b1990v27HzqUj91zIF/y4+/JI4eW8p1vuSmPPIV/ubrrwcdyzb99d37s/3z0qZYKALAp/v07b02SrK623PvIkTUfI9wBgNNLuPMU/PDffd5J9+9/9Gi+4Wf/KA8fWsoX//h7kiR/fPsDG37eex4+nK/97+/PT7/3E0mSv77/4FMvFgBgE/zm3ruTJEeXV/Jtb77xpI+tjkKd5VVdxwBwOk0V7lTVy6vq41V1e1W9bquLmhcLgy53/sQr87Eff9m6j3ntr91y/PYP/vqHc9Xr3pXDx9Y/OvSBg0fzqjf+aT65/7FsW5C9AQD98tjofcxa72dWRtvRjy4LdwDgdJqYHlTVIMn/TPKKJNcmeU1VXbvVhc2Tc7Yt5IWX71734//5d2/LRz/zSH77ls8kSa75t+/OW//0zrzrI/fmfbfdl3sfOZyb7/pcbr//YH7vo5893uL8eLhz812fy/ffcMu6z7+WI0sraa1l750P5Y79/ej8+eAnHxwbbLXW1hzK2Aettac8PwkAziQ33fnQKdce3451bEy401rLx+45sGV1AcDZqCb9wFpVX5Hk37fWXja6//okaa395/U+57rrrmt79+7dzDrnwkf2PZxvfsOfJEmu/+qr86YP3LHpf8aOxS5f8IzzsrTc8oWXnJ8Ldi7mxk89mKefuy13PnAo524f5Cufc1F++c/uyiW7duSzB4ZB0dc8b092LAxyxwMHs3PbQv7i7odz9Z5zc8f+x/KyL7o4Tz93W2646e7805c8+/jRpq21rLbhUaerLXns6HL+Yt/Deenzn5Ek2TY4ORt86LFjue2zB/KS51x0/NrPrfE9eM2Lr8z2hS4LXaVl+Ebw0LHl/ObN+/L4y/GfvOSqLA66LK+0PHZ0OQePLecZ52/PtkGXldWW5dWWQVdZ6CpHl1ezbaHLkaWVPPjYsVzxtHOG9Wf0ZGNe4i3J8krL9sW1c86HDy1l26DyWx/6TFZWW/7Rl12ZyrBr63GPHV3ObfceyJdccUH2fe5wnnXROanU5//8JJXKQ48dze6dizlweDnnbl/Y9M6s1loeObyUC87Z9vk/tzb1j9gUR5dWc2R5JefvWBheaMP/DkdHwd7ObQtpaWnt8VAt6brKoNv8L+bRI0tZ6LrsWByMSjnhxXLi66aSro/fTObC6uh1vBWv4c300MFjedq52zb1/xvHlldz6Nhydu1czG/8+d353KGlXHPprnz1F150/P/3ff++cLLb7j2Q9398/ynXv/tvPTsLXeV9f3V/br//YL7lS56Z//vhe/KiKy/IFU8/J3c9eCjn71jI8y4+Pw8fXsrbb96X7/ma52xaXR/85IO595HD+fsvunzTnnNePHpkKedtX+zl3/kAffFNL3zmmocizaOqurm1dt0Try9M8bmXJbn7hPv7knzZGn/A9UmuT5Irr7zySZY53154+QW58ydemUcOLWX3OYt5/Suen0PHVvLphw7lrgcP5eOffTS7dy7k6PJqLr1gZz5y98N52rnbcnRpJfcdOJqVNgwyHjh4NEsrLZfu3pGd2wZZ7LpceN62fOK+R3Pp7p1ZaS0PPHo0X3z57nRVqUoePbKc51+yKwtd5fKn7cxrXnxFnnH+jjxw8Gje87H7csmuHdm9czHnbB9k147F7NqxkIt37UiN6m6t5euueUYu2b09g65LJelq+EN1jd4tPPzYsRxbXs3Fu3ZkaXk1iyeEE60Nj4g/tLSSC84Z/nDQWvJVz70oR5ZW8qwLz80ffmJ/XvWiy3PhudvSdZXlldXjb0SOLq3mVS+6PI8dXc7OxUEu3rUjSbLQVc7bvpBBV3nwsWOjH5CGP2gfOLyUndsWcnhpJedsG2TboMtqazl/x8Lx560Mb6z1hqe14fUjSytZHKwdtHSV7Fwc5PqvvjqPHlnKRedtT0uOB2BJcv6OhTx06FjO37GYnduOZffOxWEgMfpDTwwMnnbOYgZdl8VBZee2wZN4la3/dWRU166dC8ev99G521oeONiye+fiSf99Vkev/3O2LRx/Xdfxj23NcM6FrnJsefX49yz5/Gvm8bqSz/9wDk/W0eXVbO/5VtujS6ufD103y/bh2r1g57Z8/bUXJ0l27Vg8vv4fD3KZHxefvyNfcfWFWW3Df2T5xH2P5qLztuecbYPs3DbIpbt35JpLd+V5l5yfr7/24lxzyfl56NCxXPn0c7JzcZDzdixk187FvOIFl+S87Zv3evvK51yYBw8e29TnnCdn69cNMK2FwZmfgE/TufOtSV7WWvtno/vfkeTFrbXvW+9zztbOHQAAAICtsl7nzjT/jLgvyRUn3L88yT2bVRgAAAAAT9404c6fJ3luVT27qrYleXWSd25tWQAAAABMY+IG3dbaclW9NsnvJxkkeUtr7dYtrwwAAACAiaaavtZa+90kv7vFtQAAAACwQf0+ugMAAACAsYQ7AAAAAHNMuAMAAAAwx4Q7AAAAAHNMuAMAAAAwx4Q7AAAAAHNMuAMAAAAwx4Q7AAAAAHNMuAMAAAAwx6q1tvlPWrU/yV2b/sSn30VJHph1ETAHrBWYjrUC07FWYDrWCkznTForz2qt7XnixS0Jd84UVbW3tXbdrOuAvrNWYDrWCkzHWoHpWCswnbNhrdiWBQAAADDHhDsAAAAAc0y4M96bZl0AzAlrBaZjrcB0rBWYjrUC0znj14qZOwAAAABzTOcOAAAAwBwT7qyjql5eVR+vqtur6nWzrgdOp6q6oqr+oKpuq6pbq+oHRtefXlXvraq/Hv3+tBM+5/Wj9fLxqnrZCdf/ZlX95ehjP1tVNYuvCbZSVQ2q6paq+p3RfWsFnqCqLqiqt1fVX43+fvkKawVOVVU/OHr/9dGquqGqdlgrkFTVW6rq/qr66AnXNm1tVNX2qvr10fUbq+qq0/n1PVXCnTVU1SDJ/0zyiiTXJnlNVV0726rgtFpO8kOttWuSfHmS7x2tgdcleV9r7blJ3je6n9HHXp3ki5K8PMn/Gq2jJHljkuuTPHf06+Wn8wuB0+QHktx2wn1rBU71P5K8u7X2/CRfnOGasVbgBFV1WZLvT3Jda+0FSQYZrgVrBZJfzKmv481cG9+d5HOttS9I8tNJfnLLvpItINxZ24uT3N5au6O1dizJ25J8y4xrgtOmtXZva+1Do9uPZvgG/LIM18FbRw97a5K/N7r9LUne1lo72lr7VJLbk7y4qi5Nsqu19sE2HPD1Syd8DpwRquryJK9M8uYTLlsrcIKq2pXkq5P8QpK01o611h6OtQJrWUiys6oWkpyT5J5YK5DW2geSPPSEy5u5Nk58rrcn+dp56ngT7qztsiR3n3B/3+ganHVG7YhfmuTGJBe31u5NhgFQkmeMHrbemrlsdPuJ1+FM8jNJfiTJ6gnXrBU42dVJ9if536MtjG+uqnNjrcBJWmufSfLfknw6yb1JHmmtvSfWCqxnM9fG8c9prS0neSTJhVtW+SYT7qxtrXTOsWKcdarqvCS/leRfttYOjHvoGtfamOtwRqiqb0xyf2vt5mk/ZY1r1gpng4UkL0ryxtbalyZ5LKPW+XVYK5yVRotJFDwAAAIUSURBVPNCviXJs5M8M8m5VfXt4z5ljWvWCjy5tTHX60a4s7Z9Sa444f7lGbZDwlmjqhYzDHZ+tbX2jtHl+0atjBn9fv/o+nprZt/o9hOvw5niJUm+uaruzHAL70ur6ldircAT7Uuyr7V24+j+2zMMe6wVONnXJflUa21/a20pyTuSfGWsFVjPZq6N458z2ha5O6duA+st4c7a/jzJc6vq2VW1LcNBTO+ccU1w2oz2lv5Ckttaaz91wofemeS7Rre/K8n/PeH6q0cT5p+d4WCym0atkY9W1ZePnvM7T/gcmHuttde31i5vrV2V4d8V/6+19u2xVuAkrbXPJrm7qp43uvS1ST4WawWe6NNJvryqzhm9xr82w9mH1gqsbTPXxonP9Q8yfF83N507C7MuoI9aa8tV9dokv5/hhPq3tNZunXFZcDq9JMl3JPnLqvrw6Nq/TvITSX6jqr47wzcf35okrbVbq+o3Mnyjvpzke1trK6PP+54MJ9vvTPJ7o19wprNW4FTfl+RXR/9wdkeSf5LhPzRaKzDSWruxqt6e5EMZvvZvSfKmJOfFWuEsV1U3JPmaJBdV1b4k/y6b+57rF5L8clXdnmHHzqtPw5e1aWqOgigAAAAAnsC2LAAAAIA5JtwBAAAAmGPCHQAAAIA5JtwBAAAAmGPCHQAAAIA5JtwBAAAAmGPCHQAAAIA5JtwBAAAAmGP/H/QvByQ96ukRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.title(\"cost\")\n",
    "plt.plot(cost_epoch, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== prediction ====\n",
      "input_value: \t\t['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis', 'kin']\n",
      "prediction_value: \t['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
      "accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.cast(tf.argmax(model, 1), tf.int32)\n",
    "prediction_check = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n",
    "\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "predict, accuracy_val = sess.run([prediction, accuracy], \n",
    "                                 feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "\n",
    "\n",
    "predict_word = []\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_word.append(val[:3] + last_char)\n",
    "    \n",
    "print(\"\\n==== prediction ====\")\n",
    "print(\"input_value: \\t\\t{}\".format([w[:3] for w in seq_data]))\n",
    "print(\"prediction_value: \\t{}\".format(predict_word))\n",
    "print(\"accuracy: {:.3f}\".format(accuracy_val))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.ipynb 에서 attention 개념 위해 사용하는 toy 코드\n",
    "\n",
    "<p> &nbsp;\n",
    "    \n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "<p> &nbsp;\n",
    "    \n",
    "### [과제] 실행시간이 오래 걸림 . 저장된 모델 불러오는 기능을 추가.  \n",
    "    \n",
    "### [과제] 구글 번역기로 한글 charbot 데이터를 영어로 번역하고 탐구."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3318\n",
      "Number of unique input tokens: 75\n",
      "Number of unique output tokens: 891\n",
      "Max sequence length for inputs: 537\n",
      "Max sequence length for outputs: 298\n",
      "Train on 2654 samples, validate on 664 samples\n",
      "Epoch 1/100\n",
      "2654/2654 [==============================] - 473s 178ms/step - loss: 0.6580 - accuracy: 0.9389 - val_loss: 0.4219 - val_accuracy: 0.9375\n",
      "Epoch 2/100\n",
      "2654/2654 [==============================] - 570s 215ms/step - loss: 0.2244 - accuracy: 0.9626 - val_loss: 0.4568 - val_accuracy: 0.9375\n",
      "Epoch 3/100\n",
      " 192/2654 [=>............................] - ETA: 9:17 - loss: 0.2123 - accuracy: 0.9642"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-41f73fc07caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m           validation_split=0.2)\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;31m# Save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data_nmt/data/s2s.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 3 # 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'data_nmt/data/kor.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, rest = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('./data_nmt/data/s2s.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
