{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "Nt432JiJgboz",
    "outputId": "df4c9ae6-9df1-4a6d-f240-5123f887bd9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-3-12a434e29c1f>:55: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-12a434e29c1f>:59: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch: 0400 cost = 0.000000\n",
      "Epoch: 0800 cost = 0.000369\n",
      "Epoch: 1200 cost = 0.000000\n",
      "Epoch: 1600 cost = 0.000000\n",
      "Epoch: 2000 cost = 0.000000\n",
      "['ich', 'mochte', 'ein', 'bier', 'P'] -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code by Tae Hwan Jung(Jeff Jung) @graykode\n",
    "import tensorflow.compat.v1  as tf\n",
    "tf.disable_eager_execution()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# Parameter\n",
    "n_step = 5  # maxium number of words in one sentence(=number of time steps)\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "    return input_batch, output_batch, target_batch\n",
    "\n",
    "# Model\n",
    "enc_inputs = tf.placeholder(tf.float32, [None, None, n_class])  # [batch_size, n_step, n_class]\n",
    "dec_inputs = tf.placeholder(tf.float32, [None, None, n_class])  # [batch_size, n_step, n_class]\n",
    "targets = tf.placeholder(tf.int64, [1, n_step])  # [batch_size, n_step], not one-hot\n",
    "\n",
    "# Linear for attention\n",
    "attn = tf.Variable(tf.random_normal([n_hidden, n_hidden]))\n",
    "out = tf.Variable(tf.random_normal([n_hidden * 2, n_class]))\n",
    "\n",
    "def get_att_score(dec_output, enc_output):  # enc_output [n_step, n_hidden]\n",
    "    score = tf.squeeze(tf.matmul(enc_output, attn), 0)  # score : [n_hidden]\n",
    "    dec_output = tf.squeeze(dec_output, [0, 1])  # dec_output : [n_hidden]\n",
    "    return tf.tensordot(dec_output, score, 1)  # inner product make scalar value\n",
    "\n",
    "def get_att_weight(dec_output, enc_outputs):\n",
    "    attn_scores = []  # list of attention scalar : [n_step]\n",
    "    enc_outputs = tf.transpose(enc_outputs, [1, 0, 2])  # enc_outputs : [n_step, batch_size, n_hidden]\n",
    "    for i in range(n_step):\n",
    "        attn_scores.append(get_att_score(dec_output, enc_outputs[i]))\n",
    "\n",
    "    # Normalize scores to weights in range 0 to 1\n",
    "    return tf.reshape(tf.nn.softmax(attn_scores), [1, 1, -1])  # [1, 1, n_step]\n",
    "\n",
    "model = []\n",
    "Attention = []\n",
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    # enc_outputs : [batch_size(=1), n_step(=decoder_step), n_hidden(=128)]\n",
    "    # enc_hidden : [batch_size(=1), n_hidden(=128)]\n",
    "    enc_outputs, enc_hidden = tf.nn.dynamic_rnn(enc_cell, enc_inputs, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "\n",
    "    inputs = tf.transpose(dec_inputs, [1, 0, 2])\n",
    "    hidden = enc_hidden\n",
    "    for i in range(n_step):\n",
    "        # time_major True mean inputs shape: [max_time, batch_size, ...]\n",
    "        dec_output, hidden = tf.nn.dynamic_rnn(dec_cell, tf.expand_dims(inputs[i], 1),\n",
    "                                               initial_state=hidden, dtype=tf.float32, time_major=True)\n",
    "        attn_weights = get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "        Attention.append(tf.squeeze(attn_weights))\n",
    "\n",
    "        # matrix-matrix product of matrices [1, 1, n_step] x [1, n_step, n_hidden] = [1, 1, n_hidden]\n",
    "        context = tf.matmul(attn_weights, enc_outputs)\n",
    "        dec_output = tf.squeeze(dec_output, 0)  # [1, n_step]\n",
    "        context = tf.squeeze(context, 1)  # [1, n_hidden]\n",
    "\n",
    "        model.append(tf.matmul(tf.concat((dec_output, context), 1), out))  # [n_step, batch_size(=1), n_class]\n",
    "\n",
    "trained_attn = tf.stack([Attention[0], Attention[1], Attention[2], Attention[3], Attention[4]], 0)  # to show attention matrix\n",
    "model = tf.transpose(model, [1, 0, 2])  # model : [n_step, n_class]\n",
    "prediction = tf.argmax(model, 2)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "# Training and Test\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(2000):\n",
    "        input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "        _, loss, attention = sess.run([optimizer, cost, trained_attn],\n",
    "                                      feed_dict={enc_inputs: input_batch, dec_inputs: output_batch, targets: target_batch})\n",
    "\n",
    "        if (epoch + 1) % 400 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    predict_batch = [np.eye(n_class)[[word_dict[n] for n in 'P P P P P'.split()]]]\n",
    "    result = sess.run(prediction, feed_dict={enc_inputs: input_batch, dec_inputs: predict_batch})\n",
    "    print(sentences[0].split(), '->', [number_dict[n] for n in result[0]])\n",
    "\n",
    "    # Show Attention\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq(Attention)-Tensor.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
