{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def data_sequencing(path):\n",
    "    data=[]\n",
    "    with open(path,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line=line.strip()\n",
    "            index,context=line.split(' ', 1)\n",
    "            if '\\t' in line:\n",
    "                query,answer,supporting=context.split('\\t')\n",
    "                data.append([index,query,answer,supporting])\n",
    "            else:\n",
    "                data.append([index,context,'',''])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data_sequencing('../bAbI/tasks_1-20_v1-2/en/qa12_conjunction_train.txt')\n",
    "test_data=data_sequencing('../bAbI/tasks_1-20_v1-2/en/qa12_conjunction_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Query</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Supporting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John and Mary travelled to the hallway.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sandra and Mary journeyed to the bedroom.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Where is Mary?</td>\n",
       "      <td>bedroom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mary and Daniel travelled to the bathroom.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Daniel and Sandra journeyed to the office.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Where is Mary?</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Daniel and Mary went to the bedroom.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Daniel and Sandra travelled to the hallway.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Where is Sandra?</td>\n",
       "      <td>hallway</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Mary and Sandra journeyed to the garden.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index                                        Query    Answer Supporting\n",
       "0     1      John and Mary travelled to the hallway.                     \n",
       "1     2    Sandra and Mary journeyed to the bedroom.                     \n",
       "2     3                              Where is Mary?    bedroom          2\n",
       "3     4   Mary and Daniel travelled to the bathroom.                     \n",
       "4     5   Daniel and Sandra journeyed to the office.                     \n",
       "5     6                              Where is Mary?   bathroom          4\n",
       "6     7         Daniel and Mary went to the bedroom.                     \n",
       "7     8  Daniel and Sandra travelled to the hallway.                     \n",
       "8     9                            Where is Sandra?    hallway          8\n",
       "9    10     Mary and Sandra journeyed to the garden.                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train=pd.DataFrame(train_data,columns=['Index','Query','Answer','Supporting'])\n",
    "df_test=pd.DataFrame(test_data,columns=['Index','Query','Answer','Supporting'])\n",
    "\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer=Tokenizer(filters='!?\"#$%&()*+,-/:;<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(df_train['Query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'to': 2,\n",
       " 'the': 3,\n",
       " 'daniel': 4,\n",
       " 'john': 5,\n",
       " 'sandra': 6,\n",
       " 'mary': 7,\n",
       " 'where': 8,\n",
       " 'is': 9,\n",
       " 'went': 10,\n",
       " 'journeyed': 11,\n",
       " 'moved': 12,\n",
       " 'back': 13,\n",
       " 'travelled': 14,\n",
       " 'hallway.': 15,\n",
       " 'kitchen.': 16,\n",
       " 'garden.': 17,\n",
       " 'bathroom.': 18,\n",
       " 'bedroom.': 19,\n",
       " 'office.': 20}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 특징 / QA12\n",
    "1. 한 query에 사람이 두 명 씩 나옴.  \n",
    "    : 문장 번역시 `name`을 길이가 2인 list로\n",
    "2. `back`은 `went back`의 형태로밖에 나타나지 않음  \n",
    "    : `went`를 봤을 시 뒷 단어를 보고 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca = {\n",
    "    'name': {\n",
    "        'daniel': '동수',\n",
    "        'john'  : '준석',\n",
    "        'sandra': '수아',\n",
    "        'mary'  : '민경'\n",
    "    },\n",
    "    'verb': {\n",
    "        'journeyed': '여행했다.',\n",
    "        'moved'    : '이동했다.',\n",
    "        'went'     : '갔다.',\n",
    "        'travelled': '여행했다.'\n",
    "    },\n",
    "    'place': {\n",
    "        'hallway' : '복도',\n",
    "        'kitchen' : '부엌',\n",
    "        'garden'  : '정원',\n",
    "        'bathroom': '욕실',\n",
    "        'bedroom' : '침실',\n",
    "        'office'  : '사무실'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john', 'and', 'mary', 'travelled', 'to', 'the', 'hallway']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "text_to_word_sequence(df_test['Query'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조사 변경\n",
    "# https://github.com/myevan/pyjosa/blob/master/pyjosa.py 참조\n",
    "def josa(text, input):\n",
    "    if input == '은는':\n",
    "        if (ord(text[-1])- 0xac00)%28 != 0: # 종성이 있을 때\n",
    "                output = '은 '\n",
    "        else:\n",
    "                output = '는 '\n",
    "    elif input == '와과':\n",
    "        if (ord(text[-1])- 0xac00)%28 != 0: # 종성이 있을 때\n",
    "                output = '과 '\n",
    "        else:\n",
    "                output = '와 '\n",
    "    elif input == '으로':\n",
    "        if (ord(text[-1])- 0xac00)%28 in [0,8]: # 종성이 없거나 ㄹ일 때\n",
    "                output = '로 '\n",
    "        else:\n",
    "                output = '으로 '\n",
    "    return(text+output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_translation(data):\n",
    "\n",
    "    query_tr=[]\n",
    "    for query in data['Query']:\n",
    "        tokenized=text_to_word_sequence(query)\n",
    "        name, verb, place = [], '', ''\n",
    "        for word in tokenized:\n",
    "            if word in voca['name'].keys():\n",
    "                name.append(voca['name'][word])\n",
    "            elif word in voca['verb'].keys():\n",
    "                if word == 'went' and tokenized[tokenized.index(word)+1] == 'back':\n",
    "                    verb = '돌아왔다.'\n",
    "                else:\n",
    "                    verb = voca['verb'][word]\n",
    "            elif word in voca['place'].keys():\n",
    "                place = voca['place'][word]\n",
    "\n",
    "        # assemble\n",
    "        if tokenized[0] == 'where':\n",
    "            if place == '':\n",
    "                place = '어디'\n",
    "            query_tr.append(josa(name[0],'은는') + place + '에 있습니까?')\n",
    "        else:\n",
    "            query_tr.append(josa(name[0],'와과')+josa(name[1],'은는')  +josa(place,'으로')+verb)\n",
    "                \n",
    "\n",
    "    answer_tr=[]\n",
    "    for answer in data['Answer']:\n",
    "        if answer:\n",
    "            answer_tr.append(voca['place'][answer])\n",
    "        else:\n",
    "            answer_tr.append(answer)\n",
    "       \n",
    "    return query_tr,answer_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr=data_translation(df_train)\n",
    "test_tr=data_translation(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reconstruction(original_data,translated_data):\n",
    "    \n",
    "    data=[]\n",
    "    for i in range(len(original_data)):\n",
    "        index,supporting=original_data[i][0],original_data[i][3]\n",
    "        query,answer=translated_data[0][i],translated_data[1][i]\n",
    "                                                      \n",
    "        data.append([index,query,answer,supporting])\n",
    "                                                      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tr=pd.DataFrame(data_reconstruction(train_data,train_tr),\n",
    "                         columns=['Index','Query','Answer','Supporting'])\n",
    "df_test_tr=pd.DataFrame(data_reconstruction(test_data,test_tr),\n",
    "                        columns=['Index','Query','Answer','Supporting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tr.to_csv('./qa12_conjunction_train_kr.csv',index=False, encoding = 'utf-8-sig')\n",
    "df_test_tr.to_csv('./qa12_conjunction_test_kr.csv',index=False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
