{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 텐서플로(Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Dropbox\\WinPython37F\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y=f(Wx+b),$$\n",
    "$x$: 입력벡터, $b$: 편향벡터, $W$: 가중치 행렬, $f$: 활성화 함수  \n",
    "원래는 변수를 직접 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([5,10], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y = tf.matmul(W,x) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense로 쉽게 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 다시 호출하면서 입력값 설정\n",
    "dense = tf.keras.layers.Dense( ... )\n",
    "output = dense(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "output = tf.keras.layers.Dense( ... )(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "help(tf.keras.layers.Dense)\n",
    "```\n",
    "~~~\n",
    "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
    "\n",
    "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
    " |  Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    " |  \n",
    " |  Just your regular densely-connected NN layer.\n",
    " |  \n",
    " |  `Dense` implements the operation:\n",
    " |  `output = activation(dot(input, kernel) + bias)`\n",
    " |  where `activation` is the element-wise activation function\n",
    " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
    " |  created by the layer, and `bias` is a bias vector created by the layer\n",
    " |  (only applicable if `use_bias` is `True`).\n",
    " |  \n",
    " |  Note: If the input to the layer has a rank greater than 2, then\n",
    " |  it is flattened prior to the initial dot product with `kernel`.\n",
    " ~~~\n",
    "|  | |\n",
    "| ---|---|\n",
    "| units              | 출력값의 크기. Integer 또는 Long  |\n",
    "| activation         | 활성화 함수  |\n",
    "| use_bias           | 편향($b$)의 사용여부  |\n",
    "| kernel_initializer | 가중치($W$) 초기화 함수  |\n",
    "| bias_initializer   | 편향 초기화 함수  |\n",
    "| kernel_regularizer | 가중치 정규화 방법  |\n",
    "| bias_regularizer   | 편향 정규화 방법  |\n",
    "| activity_regulizer | 출력 값 정규화 방법|\n",
    "| kernal_constraint  | Optimizer에 의해 업데이트된 이후에<br/>가중치에 적용되는 부가적인 제약 함수|\n",
    "| bias_constraint  | Optimizer에 의해 업데이트된 이후에<br/>편향에 적용되는 부가적인 제약 함수|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex) 10개의 노드를 가지는 은닉층이 있고 최종 출력 값은 2개의 노드가 있는 신경망 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20,1)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합(Overfitting) - 정규화(Regularization) 방법을 사용해서 해결.  \n",
    "대표적인 방법이 dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 다시 호출하면서 입력값 설정\n",
    "dropout= tf.keras.layers.Dropout( ... )\n",
    "output = dropout(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "output = tf.keras.layers.Dropout( ... )(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "help(tf.keras.layers.Dropout)\n",
    "```\n",
    "```\n",
    "Help on class Dropout in module tensorflow.python.keras.layers.core:\n",
    "\n",
    "class Dropout(tensorflow.python.keras.engine.base_layer.Layer)\n",
    " |  Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
    " |  \n",
    " |  Applies Dropout to the input.\n",
    " |  \n",
    " |  Dropout consists in randomly setting\n",
    " |  a fraction `rate` of input units to 0 at each update during training time,\n",
    " |  which helps prevent overfitting.\n",
    " |  \n",
    " |  Arguments:\n",
    " |    rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    " |    noise_shape: 1D integer tensor representing the shape of the\n",
    " |      binary dropout mask that will be multiplied with the input.\n",
    " |      For instance, if your inputs have shape\n",
    " |      `(batch_size, timesteps, features)` and\n",
    " |      you want the dropout mask to be the same for all timesteps,\n",
    " |      you can use `noise_shape=(batch_size, 1, features)`.\n",
    " |    seed: A Python integer to use as random seed.\n",
    " |  \n",
    " |  Call arguments:\n",
    " |    inputs: Input tensor (of any rank).\n",
    " |    training: Python boolean indicating whether the layer should behave in\n",
    " |      training mode (adding dropout) or in inference mode (doing nothing).\n",
    " |  \n",
    " |  Method resolution order:\n",
    " |      Dropout\n",
    " |      tensorflow.python.keras.engine.base_layer.Layer\n",
    " |      tensorflow.python.module.module.Module\n",
    " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
    " |      tensorflow.python.training.tracking.base.Trackable\n",
    " |      builtins.object\n",
    " |  \n",
    " |  Methods defined here:\n",
    " |  \n",
    " |  __init__(self, rate, noise_shape=None, seed=None, **kwargs)\n",
    " ```\n",
    " \n",
    " |||\n",
    " |---|---|\n",
    " |rate|드롭아웃을 적용할 확률($\\in[0,1]$).<br/>예시로 0.2이면 전체 입력값 중 20%를 0으로 만듦|\n",
    " |noise_shape|정수형의 1D-tensor값을 받음.<br/>지정하면 특정 값에만 드롭아웃 적용|\n",
    " |seed|시드|\n",
    " \n",
    " `tf.nn` 모듈에도 dropout이 있는데, 거기는 지정된 rate만큼만 남기는 방식."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20,1)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.5)(input)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(dropout)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||합성곱의 방향|출력값|\n",
    "|:---|:---|:---|\n",
    "|Conv1D|한 방향(가로)|1-D Array(vector)|\n",
    "|Conv2D|두 방향(가로, 세로)|2-D Array(matrix)|\n",
    "|Conv3D|세 방향(가로, 세로, 높이)|3-D Array(tensor)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig2.2.jpg\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 다시 호출하면서 입력값 설정\n",
    "conv1d = tf.keras.layers.Conv1D( ... )\n",
    "output = conv1d(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "output = tf.keras.layers.Conv1D( ... )(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "help(tf.keras.layers.Conv1D)\n",
    "```\n",
    "```\n",
    "Help on class Conv1D in module tensorflow.python.keras.layers.convolutional:\n",
    "\n",
    "class Conv1D(Conv)\n",
    " |  Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    " |  \n",
    " |  1D convolution layer (e.g. temporal convolution).\n",
    " |  \n",
    " |  This layer creates a convolution kernel that is convolved\n",
    " |  with the layer input over a single spatial (or temporal) dimension\n",
    " |  to produce a tensor of outputs.\n",
    " |  If `use_bias` is True, a bias vector is created and added to the outputs.\n",
    " |  Finally, if `activation` is not `None`,\n",
    " |  it is applied to the outputs as well.\n",
    " |  \n",
    " |  When using this layer as the first layer in a model,\n",
    " |  provide an `input_shape` argument\n",
    " |  (tuple of integers or `None`, e.g.\n",
    " |  `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\n",
    " |  or `(None, 128)` for variable-length sequences of 128-dimensional vectors.\n",
    " ```\n",
    " Dense와 비슷한 구조\n",
    " \n",
    " |||\n",
    " |---|---|\n",
    " |filters|필터의 개수. Integer. 출력의 차원수,|\n",
    " |kernel_size|필터의 크기. Int, List[Int], Tuple[Int].|\n",
    " |strides|스트라이드의 값. Int, List[Int], Tuple[Int].<br/>1이 아닌 값을 지정할 시 `dilation_rate`는 1로 고정.|\n",
    " |padding|패딩 방법. \"VALID\" 또는 \"SAME\".|\n",
    " |data_format|데이터의 표현 방법. \"channel_last\" 또는 \"channel_last\".<br/>channel_last의 경우 데이터는 (batch, length, channels)형태,<br/>channel_first의 경우 데이터는 (batch, channels, length)형태|\n",
    " |dilation_rate|dilation 합성곱 상용시 적용할 dilation 값. Int, List[Int], Tuple[Int].<br/>1이 아닌 값을 지정할 시 `strides`는 1로 고정 |\n",
    " |activation|활성화 함수|\n",
    "| use_bias           | 편향($b$)의 사용여부  |\n",
    "| kernel_initializer | 가중치($W$) 초기화 함수  |\n",
    "| bias_initializer   | 편향 초기화 함수  |\n",
    "| kernel_regularizer | 가중치 정규화 방법  |\n",
    "| bias_regularizer   | 편향 정규화 방법  |\n",
    "| activity_regulizer | 출력 값 정규화 방법|\n",
    "| kernal_constraint  | Optimizer에 의해 업데이트된 이후에<br/>가중치에 적용되는 부가적인 제약 함수|\n",
    "| bias_constraint  | Optimizer에 의해 업데이트된 이후에<br/>편향에 적용되는 부가적인 제약 함수|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 사용법\n",
    "INPUT_SIZE = (1,28,28)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "        filters = 10,\n",
    "        kernel_size = 3,\n",
    "        padding = 'same',\n",
    "        activation = tf.nn.relu)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값에 드롭아웃을 적용\n",
    "INPUT_SIZE = (1,28,28)\n",
    "is_training = True\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(input)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "        filters = 10,\n",
    "        kernel_size = 3,\n",
    "        padding = 'same',\n",
    "        activation = tf.nn.relu)(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.MaxPool1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링(pooling)  \n",
    "합성곱 신경망과 함께 쓰이는 기법 중 하나. 보통 피처 맵(feature map)의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용.\n",
    "\n",
    "- 맥스 풀링(max-pooling): 피처 맵에 대해 최댓값만을 뽑아냄 (이 책에서 주로 쓸 방법).\n",
    "- 평균 풀링(average-pooling): 피처 맵에 대해 전체 값들을 평균한 값을 뽑음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱과 같이 세 가지 형태의 모델.\n",
    "- MaxPool1D (주로 쓸 모델)\n",
    "- MaxPool2D\n",
    "- MaxPool3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 apply 함수를 이용해 입력값 설정\n",
    "max_pool = tf.keras.layers.MaxPool1D( ... )\n",
    "max_pool.apply(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "max_pool = tf.keras.layers.MaxPool1D( ... )(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "help(tf.keras.layers.MaxPool1D)\n",
    "```\n",
    "```\n",
    "Help on class MaxPooling1D in module tensorflow.python.keras.layers.pooling:\n",
    "\n",
    "class MaxPooling1D(Pooling1D)\n",
    " |  MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_last', **kwargs)\n",
    " |  \n",
    " |  Max pooling operation for temporal data.\n",
    " |  \n",
    " |  Arguments:\n",
    " |    pool_size: Integer, size of the max pooling windows.\n",
    " |    strides: Integer, or None. Factor by which to downscale.\n",
    " |      E.g. 2 will halve the input.\n",
    " |      If None, it will default to `pool_size`.\n",
    " |    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
    " |    data_format: A string,\n",
    " |      one of `channels_last` (default) or `channels_first`.\n",
    " |      The ordering of the dimensions in the inputs.\n",
    " |      `channels_last` corresponds to inputs with shape\n",
    " |      `(batch, steps, features)` while `channels_first`\n",
    " |      corresponds to inputs with shape\n",
    " |      `(batch, features, steps)`.\n",
    "```\n",
    "|||\n",
    "|---|---|\n",
    "|pool_size|풀링을 적용할 필터의 크기. Int.|\n",
    "|strides|스트라이드의 값. Int, None.|\n",
    "|padding|패딩 방법. \"valid\" 또는 \"same\".|\n",
    " |data_format|데이터의 표현 방법. \"channel_last\" 또는 \"channel_last\".<br/>channel_last의 경우 데이터는 (batch, length, channels)형태,<br/>channel_first의 경우 데이터는 (batch, channels, length)형태|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Flatten`: 행렬을 벡터로. 별다른 인자값 설정 없이도 사용 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (1,28,28)\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "        filters = 10,\n",
    "        kernel_size = 3,\n",
    "        padding = 'same',\n",
    "        activation = tf.nn.relu)(dropout)\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = 'same')(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(units = 50, activation = tf.nn.relu)(flatten)\n",
    "output = tf.keras.layers.Dense(units = 10, cativation = tf.nn.softmax)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
