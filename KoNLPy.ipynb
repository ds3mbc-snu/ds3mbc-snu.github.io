{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoNLPy\n",
    "- 한글 자연어 처리를 쉽고 간결하게 처리할 수 있도록 만들어진 오픈소스 라이브러리\n",
    "- 어절 단위에 대한 토크나이징은 NLTK로 충분히 해결할 수 있음. 여기서는 형태소 단위 위주\n",
    "- Java 1.7 이상 + 환경변수 설정 필요\n",
    "\n",
    "## 형태소 분석 및 품사 태깅\n",
    "형태소[명사]: 의미를 가지는 가장 작은 단위.  \n",
    "KoNLPy에 포함된 형태소 분석기:\n",
    "- Hannanum\n",
    "- Kkma\n",
    "- Komoran\n",
    "- Mecab\n",
    "- Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Okt in module konlpy.tag._okt object:\n",
      "\n",
      "class Okt(builtins.object)\n",
      " |  Okt(jvmpath=None, max_heap_size=1024)\n",
      " |  \n",
      " |  Wrapper for `Open Korean Text <https://github.com/open-korean-text/open-korean-text>`_.\n",
      " |  \n",
      " |  Open Korean Text is an open source Korean tokenizer written in Scala,\n",
      " |  developed by Will Hohyon Ryu.\n",
      " |  \n",
      " |  .. code-block:: python\n",
      " |  \n",
      " |      >>> from konlpy.tag import Okt\n",
      " |      >>> okt = Okt()\n",
      " |      >>> print(okt.morphs(u'단독입찰보다 복수입찰의 경우'))\n",
      " |      ['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n",
      " |      >>> print(okt.nouns(u'유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))\n",
      " |      ['항공기', '체계', '종합', '개발', '경험']\n",
      " |      >>> print(okt.phrases(u'날카로운 분석과 신뢰감 있는 진행으로'))\n",
      " |      ['날카로운 분석', '날카로운 분석과 신뢰감', '날카로운 분석과 신뢰감 있는 진행', '분석', '신뢰', '진행']\n",
      " |      >>> print(okt.pos(u'이것도 되나욬ㅋㅋ'))\n",
      " |      [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n",
      " |      >>> print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True))\n",
      " |      [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나요', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n",
      " |      >>> print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True, stem=True))\n",
      " |      [('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n",
      " |  \n",
      " |  :param jvmpath: The path of the JVM passed to :py:func:`.init_jvm`.\n",
      " |  :param max_heap_size: Maximum memory usage limitation (Megabyte) :py:func:`.init_jvm`.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, jvmpath=None, max_heap_size=1024)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  morphs(self, phrase, norm=False, stem=False)\n",
      " |      Parse phrase to morphemes.\n",
      " |  \n",
      " |  normalize(self, phrase)\n",
      " |  \n",
      " |  nouns(self, phrase)\n",
      " |      Noun extractor.\n",
      " |  \n",
      " |  phrases(self, phrase)\n",
      " |      Phrase extractor.\n",
      " |  \n",
      " |  pos(self, phrase, norm=False, stem=False, join=False)\n",
      " |      POS tagger.\n",
      " |      In contrast to other classes in this subpackage,\n",
      " |      this POS tagger doesn't have a `flatten` option,\n",
      " |      but has `norm` and `stem` options.\n",
      " |      Check the parameter list below.\n",
      " |      \n",
      " |      :param norm: If True, normalize tokens.\n",
      " |      :param stem: If True, stem tokens.\n",
      " |      :param join: If True, returns joined sets of morph and tag.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(okt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `okt.morphs(phrase, norm = False, stem = False)`\n",
    "    - phrase를 형태소 단위로 나눈다. \n",
    "    - norm: 문장을 정규화할지 여부\n",
    "    - stem: 각 단어에서 어간을 추출할지 여부\n",
    "\n",
    "- `okt.nouns(phrase)`\n",
    "    - phrase에서 명사만 뽑아낸다.\n",
    "\n",
    "- `okt.phrases(phrase)`\n",
    "    - phrase에서 어절을 뽑아낸다.\n",
    "\n",
    "- `okt.pos(phrase, norm=False, stem=False, join=False)`\n",
    "    - 각 품사를 태깅하는 역할. 주어진 텍스트를 형태소 단위로 나누고, 나눠진 각 형태소를 그에 해당하는 품사와 함게 리스트화하는 것.\n",
    "    - join: 나눠진 형태소와 품사를 '형태소/품사' 형태로 같이 붙여서 리스트화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphs():  ['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "morphs(norm=True):  ['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "morphs(stem=True):  ['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n",
      "nouns():  ['한글', '자연어', '처리', '이제']\n",
      "phrases():  ['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n",
      "pos():  [('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "pos(join=True):  ['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n"
     ]
    }
   ],
   "source": [
    "text = '한글 자연어 처리는 재밌다 이제부터 열심히 해야지ㅎㅎㅎ'\n",
    "\n",
    "print('morphs(): ',okt.morphs(text))\n",
    "print('morphs(norm=True): ',okt.morphs(text, norm=True))\n",
    "print('morphs(stem=True): ',okt.morphs(text, stem=True))\n",
    "print('nouns(): ',okt.nouns(text))\n",
    "print('phrases(): ',okt.phrases(text))\n",
    "print('pos(): ',okt.pos(text))\n",
    "print('pos(join=True): ',okt.pos(text, join=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "train_data = pd.read_csv('./nsmc-master/ratings_train.txt', header = 0, delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                    너무재밓었다그래서보는것을추천한다\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 리뷰로 전처리 연습.  \n",
    "1. 한글 문자가 아닌 것들을 모두 제거(by 정규표현식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n"
     ]
    }
   ],
   "source": [
    "review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', train_data['document'][1])\n",
    "print(review_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 불용어를 제거하기 위해 문장 단어로 나누기 + 형태소 분석기를 사용해 어간이 추출된 단어로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['당/Modifier', '신/Modifier', '은/Noun', '요/Josa', '?/Punctuation']\n"
     ]
    }
   ],
   "source": [
    "# 맞춤법과 문법 오류가 없는데 분석이 안되는 문장.\n",
    "temp = '당신은요?'\n",
    "temp_okt = okt.pos(temp, join=True)\n",
    "print(temp_okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "review_text = okt.morphs(review_text, stem = True)\n",
    "print(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
